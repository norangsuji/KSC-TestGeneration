{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mjpe7STyxkS"
      },
      "source": [
        "# KSC: LLM-Driven **Composite** Test Generation (GPT‑4o, Python)\n",
        "**Repo:** `temporalio/money-transfer-project-template-python`  \n",
        "**LLM:** OpenAI GPT‑4o  \n",
        "**Notebook 목적:** *분기 의무 + Def‑Use 체인 + 예외 경로*를 통합한 테스트를 자동 생성·실행·증분합니다."
      ],
      "id": "0mjpe7STyxkS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwYDg5FyxkT"
      },
      "source": [
        "# 3-0. 런타임 & 의존성 준비"
      ],
      "id": "4gwYDg5FyxkT"
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /contents/*"
      ],
      "metadata": {
        "id": "dwm3JhC-wlet"
      },
      "id": "dwm3JhC-wlet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-0) 런타임 & 의존성 준비  (동일 커버리지 범위 설정 포함)\n",
        "import os, sys, subprocess, pathlib, getpass, textwrap, shutil\n",
        "\n",
        "# 1) 기본 상수/경로\n",
        "REPO_URL = \"https://github.com/temporalio/money-transfer-project-template-python.git\"\n",
        "PROJECT_NAME = REPO_URL.rstrip(\"/\").split(\"/\")[-1].replace(\".git\", \"\")\n",
        "ROOT = pathlib.Path(\".\").resolve()\n",
        "PROJ = ROOT / PROJECT_NAME\n",
        "\n",
        "def sh(cmd: str, check: bool = True, cwd: pathlib.Path | None = None) -> None:\n",
        "    print(\"> \", cmd)\n",
        "    rc = subprocess.call(cmd, shell=True, cwd=str(cwd) if cwd else None)\n",
        "    if check and rc != 0:\n",
        "        raise RuntimeError(f\"Command failed (rc={rc}): {cmd}\")\n",
        "\n",
        "print(f\"Python {sys.version}\")\n",
        "print(\"ROOT:\", ROOT)\n",
        "\n",
        "# 2) 레포 클론/업데이트\n",
        "if PROJ.exists():\n",
        "    print(f\"Repo exists at {PROJ}. Pulling latest…\")\n",
        "    sh(f\"git -C {PROJ} fetch --all --prune\")\n",
        "    sh(f\"git -C {PROJ} reset --hard origin/main\")\n",
        "else:\n",
        "    sh(f\"git clone --depth=1 {REPO_URL}\")\n",
        "print(\"✅ 레포 클론/업데이트 완료\")\n",
        "\n",
        "# 3) 의존성 설치\n",
        "def pip_install(pkgs):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-U\"] + pkgs\n",
        "    print(\"> \", \" \".join(cmd))\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "pkgs_core = [\n",
        "    \"pytest\", \"pytest-asyncio\", \"pytest-mock\", \"pytest-cov\",\n",
        "    \"coverage[toml]\",\n",
        "    \"temporalio\",\n",
        "    \"lxml\",\n",
        "    \"asttokens\", \"libcst\", \"networkx\",\n",
        "    \"rich\", \"pyyaml\",\n",
        "]\n",
        "if sys.version_info < (3, 11):\n",
        "    pkgs_core.append(\"tomli\")\n",
        "\n",
        "pkgs_llm = [\n",
        "    \"openai>=1.43.0\",\n",
        "    \"httpx>=0.27.0\",\n",
        "    \"backoff>=2.2.1\",\n",
        "    \"tiktoken>=0.7.0\",\n",
        "    \"aiolimiter>=1.1.0\",\n",
        "    \"anyio>=4.4.0\",\n",
        "    \"nest_asyncio>=1.6.0\",\n",
        "    \"python-dotenv>=1.0.1\",\n",
        "    \"tqdm>=4.66.5\",\n",
        "]\n",
        "\n",
        "pip_install([\"pip\"])\n",
        "pip_install(pkgs_core)\n",
        "pip_install(pkgs_llm)\n",
        "print(\"✅ 의존성 설치 완료\")\n",
        "\n",
        "# 4) .env (OPENAI_API_KEY 등)\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "except Exception:\n",
        "    pip_install([\"python-dotenv>=1.0.1\"])\n",
        "    from dotenv import load_dotenv\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Enter OPENAI_API_KEY (필수): \").strip()\n",
        "env_lines = [\n",
        "    f\"OPENAI_API_KEY={openai_api_key}\",\n",
        "    \"OPENAI_BASE_URL=\",\n",
        "    \"OPENAI_API_VERSION=\",\n",
        "    \"OPENAI_ORG_ID=\",\n",
        "    \"AZURE_OPENAI_ENDPOINT=\",\n",
        "    \"AZURE_OPENAI_DEPLOYMENT=\",\n",
        "]\n",
        "env_path = ROOT / \".env\"\n",
        "env_path.write_text(\"\\n\".join(env_lines) + \"\\n\", encoding=\"utf-8\")\n",
        "load_dotenv(env_path)\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "print(\"✅ .env 저장 및 환경 주입 완료\")\n",
        "\n",
        "# 5) PYTHONPATH 설정 (src 레이아웃도 지원)\n",
        "os.environ[\"PROJECT_PATH\"] = str(PROJ)\n",
        "py_paths = [str(PROJ)]\n",
        "if (PROJ / \"src\").exists():\n",
        "    py_paths.insert(0, str(PROJ / \"src\"))  # src 우선\n",
        "prev_pp = os.environ.get(\"PYTHONPATH\", \"\")\n",
        "os.environ[\"PYTHONPATH\"] = \":\".join(py_paths + ([prev_pp] if prev_pp else []))\n",
        "print(\"✅ PYTHONPATH =\", os.environ[\"PYTHONPATH\"])\n",
        "\n",
        "# 6) 커버리지 source 자동 탐색 → .coveragerc 생성\n",
        "def detect_sources(proj: pathlib.Path) -> list[str]:\n",
        "    \"\"\"\n",
        "    최상위 패키지 후보를 자동 탐지:\n",
        "    - src/ 가 있으면 src/ 하위의 1depth 패키지( __init__.py 존재 )를 사용\n",
        "    - 없으면 프로젝트 루트의 1depth 패키지( __init__.py 존재 )를 사용\n",
        "    - 없으면 .py가 다수인 디렉터리(테스트/생성 제외)를 대안으로 포함\n",
        "    \"\"\"\n",
        "    candidates_root = []\n",
        "    base = proj / \"src\" if (proj / \"src\").exists() else proj\n",
        "    for child in sorted(base.iterdir()):\n",
        "        if not child.is_dir():\n",
        "            continue\n",
        "        if child.name in {\"tests\", \"generated_tests\", \".venv\", \"venv\", \".git\", \"run_artifacts\", \"htmlcov\", \"htmlcov_gen\", \"htmlcov_gen_pass\"}:\n",
        "            continue\n",
        "        if (child / \"__init__.py\").exists():\n",
        "            # coverage source 경로는 프로젝트 루트 기준으로 작성\n",
        "            rel = child.relative_to(proj)\n",
        "            candidates_root.append(str(rel))\n",
        "\n",
        "    if candidates_root:\n",
        "        return candidates_root\n",
        "\n",
        "    # fallback: __init__.py는 없지만 .py 파일 많은 디렉터리 몇 개 포함\n",
        "    fallback = []\n",
        "    for child in sorted(base.iterdir()):\n",
        "        if not child.is_dir():\n",
        "            continue\n",
        "        if child.name in {\"tests\", \"generated_tests\", \".venv\", \"venv\", \".git\", \"run_artifacts\", \"htmlcov\"}:\n",
        "            continue\n",
        "        py_count = len(list(child.glob(\"*.py\")))\n",
        "        if py_count >= 2:\n",
        "            rel = child.relative_to(proj)\n",
        "            fallback.append(str(rel))\n",
        "    return fallback or [\".\"]\n",
        "\n",
        "sources = detect_sources(PROJ)\n",
        "\n",
        "omit_patterns = [\n",
        "    \"tests/*\",\n",
        "    \"generated_tests/*\",\n",
        "    \"run_artifacts/*\",\n",
        "    \"*/site-packages/*\",\n",
        "    \".venv/*\",\n",
        "    \"venv/*\",\n",
        "]\n",
        "\n",
        "coveragerc_text = \"[run]\\nbranch = True\\n\"\n",
        "# source 리스트를 줄바꿈으로 명시\n",
        "coveragerc_text += \"source = \\n\" + \"\\n\".join(f\"    {s}\" for s in sources) + \"\\n\\n\"\n",
        "coveragerc_text += \"[report]\\nshow_missing = True\\nskip_covered = True\\n\"\n",
        "coveragerc_text += \"omit = \\n\" + \"\\n\".join(f\"    {p}\" for p in omit_patterns) + \"\\n\"\n",
        "\n",
        "(PROJ / \".coveragerc\").write_text(coveragerc_text, encoding=\"utf-8\")\n",
        "os.environ[\"COVERAGE_RCFILE\"] = str(PROJ / \".coveragerc\")  # 모든 단계에서 동일 설정 사용\n",
        "print(\"✅ .coveragerc 생성/적용 완료\")\n",
        "print(\"  - source =\", sources)\n",
        "print(\"  - omit   =\", omit_patterns)\n",
        "\n",
        "# 7) 결과 디렉토리 준비\n",
        "for d in [\"run_artifacts\", \"htmlcov\", \"reports\"]:\n",
        "    (PROJ / d).mkdir(parents=True, exist_ok=True)\n",
        "print(\"✅ 결과 디렉토리 준비 완료\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGvcId9bzF6",
        "outputId": "bae79b19-a020-411c-8137-514eab97f0ee"
      },
      "id": "yJGvcId9bzF6",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "ROOT: /content\n",
            ">  git clone --depth=1 https://github.com/temporalio/money-transfer-project-template-python.git\n",
            "✅ 레포 클론/업데이트 완료\n",
            ">  /usr/bin/python3 -m pip install -U pip\n",
            ">  /usr/bin/python3 -m pip install -U pytest pytest-asyncio pytest-mock pytest-cov coverage[toml] temporalio lxml asttokens libcst networkx rich pyyaml\n",
            ">  /usr/bin/python3 -m pip install -U openai>=1.43.0 httpx>=0.27.0 backoff>=2.2.1 tiktoken>=0.7.0 aiolimiter>=1.1.0 anyio>=4.4.0 nest_asyncio>=1.6.0 python-dotenv>=1.0.1 tqdm>=4.66.5\n",
            "✅ 의존성 설치 완료\n",
            "Enter OPENAI_API_KEY (필수): ··········\n",
            "✅ .env 저장 및 환경 주입 완료\n",
            "✅ PYTHONPATH = /content/money-transfer-project-template-python:/env/python\n",
            "✅ .coveragerc 생성/적용 완료\n",
            "  - source = ['.']\n",
            "  - omit   = ['tests/*', 'generated_tests/*', 'run_artifacts/*', '*/site-packages/*', '.venv/*', 'venv/*']\n",
            "✅ 결과 디렉토리 준비 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-1) 기준선 측정 – 기존 테스트 실행 및 커버리지 수집 (rcfile 고정 + 스코프 검증 · 견고화)\n",
        "from pathlib import Path\n",
        "import subprocess, sys, json, shutil, os, re\n",
        "from lxml import etree\n",
        "\n",
        "# ========= 0) 경로/유틸 =========\n",
        "assert 'PROJ' in globals(), \"3-0 단계에서 PROJ 변수가 설정되어 있어야 합니다.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR  = PROJ / \"run_artifacts\" / \"run1\"\n",
        "HTML_DIR = PROJ / \"htmlcov\"\n",
        "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
        "HTML_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def sh(cmd: str, check: bool = True, cwd: Path | None = None) -> int:\n",
        "    \"\"\"간단 셸 실행 (반환코드만 사용), 실패시 메시지.\"\"\"\n",
        "    print(\"> \", cmd)\n",
        "    rc = subprocess.call(cmd, shell=True, cwd=str(cwd or PROJ))\n",
        "    if check and rc != 0:\n",
        "        raise RuntimeError(f\"Command failed (rc={rc}): {cmd}\")\n",
        "    return rc\n",
        "\n",
        "def norm_path(fp: str) -> str:\n",
        "    p = Path(fp)\n",
        "    if not p.is_absolute():\n",
        "        p = (PROJ / p).resolve()\n",
        "    return str(p)\n",
        "\n",
        "def in_project(abs_path: str) -> bool:\n",
        "    try:\n",
        "        return str(PROJ) in str(Path(abs_path).resolve())\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ========= 1) .coveragerc 고정/생성 =========\n",
        "RCFILE = PROJ / \".coveragerc\"\n",
        "if not RCFILE.exists():\n",
        "    print(\"⚠️ .coveragerc가 없어 기본 템플릿을 생성합니다.\")\n",
        "    RCFILE.write_text(\n",
        "        \"[run]\\n\"\n",
        "        \"branch = True\\n\"\n",
        "        f\"data_file = {str((ART_DIR / '.coverage.baseline').as_posix())}\\n\"\n",
        "        \"\\n\"\n",
        "        \"[report]\\n\"\n",
        "        \"exclude_lines =\\n\"\n",
        "        \"    pragma: no cover\\n\"\n",
        "        \"\\n\"\n",
        "        \"[html]\\n\"\n",
        "        f\"directory = {str(HTML_DIR.as_posix())}\\n\"\n",
        "        \"\\n\"\n",
        "        \"[paths]\\n\"\n",
        "        f\"source =\\n    {str(PROJ.as_posix())}\\n\"\n",
        "        \"\\n\"\n",
        "        \"[run:omit]\\n\"\n",
        "        # 테스트/산출물/노트북 등 제외\n",
        "        \"omit =\\n\"\n",
        "        \"    */tests/*\\n\"\n",
        "        \"    tests/*\\n\"\n",
        "        \"    */generated_tests/*\\n\"\n",
        "        \"    */run_artifacts/*\\n\"\n",
        "        \"    */htmlcov/*\\n\"\n",
        "        \"    */.venv/*\\n\"\n",
        "        \"    */site-packages/*\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "rc_opt = f\" --rcfile {RCFILE}\"\n",
        "\n",
        "# ========= 2) 기준선 실행 =========\n",
        "# 과거 데이터 정리\n",
        "sh(\"coverage erase\" + rc_opt, check=False)\n",
        "\n",
        "# pytest 실행(실패해도 계속 진행해서 커버리지 산출)\n",
        "rc_run = sh(f\"{sys.executable} -m coverage run{rc_opt} -m pytest -q\", check=False)\n",
        "\n",
        "# 커버리지 산출물 생성 (항상 시도)\n",
        "json_path = PROJ / \"coverage_base.json\"\n",
        "xml_path  = PROJ / \"coverage_base.xml\"\n",
        "sh(f\"coverage json -o {json_path.name}\" + rc_opt, check=False)\n",
        "sh(f\"coverage xml  -o {xml_path.name}\"  + rc_opt, check=False)\n",
        "sh(\"coverage html\" + rc_opt, check=False)\n",
        "\n",
        "# .coverage 파일 백업(있으면)\n",
        "cov_data_file = ART_DIR / \".coverage.baseline\"\n",
        "if (ART_DIR / \".coverage.baseline\").exists() is False:\n",
        "    # RCFILE에서 data_file을 ART_DIR/.coverage.baseline으로 지정했으므로 이미 그 위치일 수 있음\n",
        "    # 혹시 프로젝트 루트에 생성됐으면 복사\n",
        "    root_cov = PROJ / \".coverage\"\n",
        "    if root_cov.exists():\n",
        "        shutil.copy2(root_cov, cov_data_file)\n",
        "\n",
        "# ========= 3) 산출물 보관 및 ‘No data’ 방어 =========\n",
        "if not json_path.exists():\n",
        "    # coverage json이 아예 없을 때, 빈 구조라도 생성\n",
        "    print(\"⚠️ coverage_base.json이 생성되지 않아 빈 구조를 만듭니다.\")\n",
        "    json_path.write_text(json.dumps({\"files\": {}}, indent=2), encoding=\"utf-8\")\n",
        "if not xml_path.exists():\n",
        "    print(\"⚠️ coverage_base.xml이 생성되지 않아 빈 구조를 만듭니다.\")\n",
        "    xml_path.write_text(\"<coverage></coverage>\", encoding=\"utf-8\")\n",
        "\n",
        "# 보관\n",
        "for src in [json_path, xml_path]:\n",
        "    if src.exists():\n",
        "        shutil.copy2(src, ART_DIR / src.name)\n",
        "\n",
        "print(\"✅ 기존 테스트 실행 및 커버리지 수집 완료 (기준선)\")\n",
        "print(\" - JSON :\", ART_DIR / 'coverage_base.json')\n",
        "print(\" - XML  :\", ART_DIR / 'coverage_base.xml')\n",
        "print(\" - HTML :\", HTML_DIR / 'index.html')\n",
        "\n",
        "# ========= 4) uncovered_map 생성 =========\n",
        "data = {}\n",
        "try:\n",
        "    data = json.loads(json_path.read_text(encoding=\"utf-8\"))\n",
        "except Exception as e:\n",
        "    print(\"⚠️ coverage_base.json 파싱 실패, 빈 구조로 진행:\", e)\n",
        "files = data.get(\"files\", {}) or {}\n",
        "\n",
        "uncovered_map: dict[str, list[int]] = {}\n",
        "for fpath, finfo in files.items():\n",
        "    # 파이썬만\n",
        "    if not str(fpath).lower().endswith(\".py\"):\n",
        "        continue\n",
        "    abs_path = norm_path(fpath)\n",
        "    # 프로젝트 외 파일 제외\n",
        "    if not in_project(abs_path):\n",
        "        continue\n",
        "    # omit 스코프 재검증(테스트/산출물 폴더 제외)\n",
        "    if any(seg in abs_path.replace(\"\\\\\", \"/\") for seg in [\n",
        "        \"/tests/\", \"tests/\", \"/generated_tests/\", \"generated_tests/\",\n",
        "        \"/run_artifacts/\", \"run_artifacts/\", \"/htmlcov/\", \"htmlcov/\"\n",
        "    ]):\n",
        "        continue\n",
        "    miss = finfo.get(\"missing_lines\", []) or []\n",
        "    if miss:\n",
        "        try:\n",
        "            uncovered_map[abs_path] = sorted(set(int(x) for x in miss))\n",
        "        except Exception:\n",
        "            # 커버리지 포맷이 예외적일 때 방어\n",
        "            uncovered_map[abs_path] = sorted({int(x) for x in map(str, miss) if str(x).isdigit()})\n",
        "\n",
        "(ART_DIR / \"uncovered_map_base.json\").write_text(\n",
        "    json.dumps(uncovered_map, indent=2, ensure_ascii=False), encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "print(f\"총 파일 수: {len(files)} / 미커버 파일 수: {len(uncovered_map)}\")\n",
        "miss_total = sum(len(v) for v in uncovered_map.values())\n",
        "print(f\"미커버 라인 수 총합: {miss_total}\")\n",
        "print(\"✅ uncovered_map_base.json 생성 완료 →\", ART_DIR / \"uncovered_map_base.json\")\n",
        "\n",
        "# ========= 4-a) 스코프 검증(테스트/생성 테스트 끼임 탐지) =========\n",
        "bad = [p for p in files.keys()\n",
        "       if \"generated_tests/\" in p or \"/tests/\" in p or str(p).startswith(\"tests/\")]\n",
        "if bad:\n",
        "    print(\"⚠️ baseline에 테스트/생성 테스트 파일이 포함되었습니다. .coveragerc의 source/omit을 확인하세요.\")\n",
        "    for b in bad[:20]:\n",
        "        print(\" -\", b)\n",
        "\n",
        "# ========= 5) observed_outcomes (브랜치 관측) =========\n",
        "observed_outcomes: dict[str, dict[int, dict]] = {}\n",
        "try:\n",
        "    xml_root = etree.parse(str(xml_path)).getroot()\n",
        "    for cls in xml_root.findall(\".//class\"):\n",
        "        filename = cls.get(\"filename\") or \"\"\n",
        "        if not filename:\n",
        "            continue\n",
        "        abs_path = norm_path(filename)\n",
        "        if not in_project(abs_path):\n",
        "            continue\n",
        "        # omit 재검증\n",
        "        if any(seg in abs_path.replace(\"\\\\\", \"/\") for seg in [\n",
        "            \"/tests/\", \"tests/\", \"/generated_tests/\", \"generated_tests/\",\n",
        "            \"/run_artifacts/\", \"run_artifacts/\", \"/htmlcov/\", \"htmlcov/\"\n",
        "        ]):\n",
        "            continue\n",
        "\n",
        "        for line in cls.findall(\"./lines/line\"):\n",
        "            if line.get(\"branch\") != \"true\":\n",
        "                continue\n",
        "            try:\n",
        "                num = int(line.get(\"number\"))\n",
        "            except Exception:\n",
        "                continue\n",
        "            cond = line.get(\"condition-coverage\")  # 예: \"50% (1/2)\"\n",
        "            covered = total = 0\n",
        "            if cond:\n",
        "                m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", cond)\n",
        "                if m:\n",
        "                    covered, total = int(m.group(1)), int(m.group(2))\n",
        "            if total == 0:\n",
        "                continue\n",
        "            observed_outcomes.setdefault(abs_path, {})[num] = {\n",
        "                \"covered\": covered,\n",
        "                \"total\": total,\n",
        "                \"ratio\": round(covered / total, 3)\n",
        "            }\n",
        "except Exception as e:\n",
        "    print(\"⚠️ coverage_base.xml 파싱 중 문제가 발생했습니다. 빈 결과로 계속합니다:\", e)\n",
        "\n",
        "(ART_DIR / \"observed_outcomes_base.json\").write_text(\n",
        "    json.dumps(observed_outcomes, indent=2, ensure_ascii=False), encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "branch_points = sum(len(v) for v in observed_outcomes.values())\n",
        "full_hit = sum(1 for fp in observed_outcomes.values() for meta in fp.values()\n",
        "               if meta[\"covered\"] == meta[\"total\"])\n",
        "half_hit = sum(1 for fp in observed_outcomes.values() for meta in fp.values()\n",
        "               if 0 < meta[\"covered\"] < meta[\"total\"])\n",
        "zero_hit = sum(1 for fp in observed_outcomes.values() for meta in fp.values()\n",
        "               if meta[\"covered\"] == 0)\n",
        "\n",
        "print(\"✅ observed_outcomes_base.json 생성 완료 →\", ART_DIR / \"observed_outcomes_base.json\")\n",
        "print(f\" - 분기 포인트 수: {branch_points}\")\n",
        "print(f\" - Full-hit  (양쪽 관측): {full_hit}\")\n",
        "print(f\" - Half-hit  (한쪽 관측): {half_hit}\")\n",
        "print(f\" - Zero-hit  (관측 0 / 미계측): {zero_hit}\")\n",
        "\n",
        "# ========= 6) 안내 =========\n",
        "if rc_run != 0:\n",
        "    print(\"ℹ️ 참고: 기준선 테스트 실행에서 실패가 있었지만, 커버리지 산출과 파싱은 계속 진행했습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHp7XI6xd1DG",
        "outputId": "7a65e13d-08be-419d-c43d-3b0a0b749a8e"
      },
      "id": "AHp7XI6xd1DG",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  coverage erase --rcfile /content/money-transfer-project-template-python/.coveragerc\n",
            ">  /usr/bin/python3 -m coverage run --rcfile /content/money-transfer-project-template-python/.coveragerc -m pytest -q\n",
            ">  coverage json -o coverage_base.json --rcfile /content/money-transfer-project-template-python/.coveragerc\n",
            ">  coverage xml  -o coverage_base.xml --rcfile /content/money-transfer-project-template-python/.coveragerc\n",
            ">  coverage html --rcfile /content/money-transfer-project-template-python/.coveragerc\n",
            "✅ 기존 테스트 실행 및 커버리지 수집 완료 (기준선)\n",
            " - JSON : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_base.json\n",
            " - XML  : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_base.xml\n",
            " - HTML : /content/money-transfer-project-template-python/htmlcov/index.html\n",
            "총 파일 수: 6 / 미커버 파일 수: 5\n",
            "미커버 라인 수 총합: 54\n",
            "✅ uncovered_map_base.json 생성 완료 → /content/money-transfer-project-template-python/run_artifacts/run1/uncovered_map_base.json\n",
            "✅ observed_outcomes_base.json 생성 완료 → /content/money-transfer-project-template-python/run_artifacts/run1/observed_outcomes_base.json\n",
            " - 분기 포인트 수: 5\n",
            " - Full-hit  (양쪽 관측): 3\n",
            " - Half-hit  (한쪽 관측): 0\n",
            " - Zero-hit  (관측 0 / 미계측): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-2) 복합 목표 생성 – AST 분석 및 목표 구조화 (모킹 플랜 자동추론 강화판)\n",
        "import ast\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Set, Optional\n",
        "\n",
        "PROJ_PATH = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ_PATH / \"run_artifacts\" / \"run1\"\n",
        "\n",
        "# ✅ baseline 산출물 사용\n",
        "UNCOVERED_JSON = ART_DIR / \"uncovered_map_base.json\"\n",
        "OBSERVED_JSON  = ART_DIR / \"observed_outcomes_base.json\"\n",
        "\n",
        "assert UNCOVERED_JSON.exists(), \"uncovered_map_base.json이 없습니다. 3-1(기준선) 단계를 먼저 실행하세요.\"\n",
        "assert OBSERVED_JSON.exists(),  \"observed_outcomes_base.json이 없습니다. 3-1(기준선) 단계를 먼저 실행하세요.\"\n",
        "\n",
        "# ---------------- utils ----------------\n",
        "def norm_abs(p: str) -> str:\n",
        "    q = Path(p)\n",
        "    if not q.is_absolute():\n",
        "        q = (PROJ_PATH / q).resolve()\n",
        "    else:\n",
        "        q = q.resolve()\n",
        "    return str(q)\n",
        "\n",
        "def rel_from_proj(abs_path: str) -> str:\n",
        "    try:\n",
        "        return str(Path(abs_path).resolve().relative_to(PROJ_PATH))\n",
        "    except Exception:\n",
        "        return abs_path\n",
        "\n",
        "def is_source(abs_path: str) -> bool:\n",
        "    \"\"\"분석 대상 소스만 허용: 테스트/산출물/가상환경 등 제외\"\"\"\n",
        "    try:\n",
        "        rel = Path(abs_path).resolve().relative_to(PROJ_PATH)\n",
        "    except Exception:\n",
        "        return False\n",
        "    s = str(rel).replace(\"\\\\\", \"/\")\n",
        "    if not s.endswith(\".py\"): return False\n",
        "    if s.startswith((\"generated_tests/\", \"tests/\", \".venv/\", \"venv/\", \"run_artifacts/\", \"htmlcov/\")):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def try_unparse(node: ast.AST) -> Optional[str]:\n",
        "    try:\n",
        "        import ast as _ast\n",
        "        if hasattr(_ast, \"unparse\"):\n",
        "            return _ast.unparse(node)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# ---------------- load inputs ----------------\n",
        "raw_uncovered: Dict[str, List[int]] = json.loads(UNCOVERED_JSON.read_text(encoding=\"utf-8\"))\n",
        "uncovered_map: Dict[str, List[int]] = {}\n",
        "for k, v in raw_uncovered.items():\n",
        "    k_abs = norm_abs(k)\n",
        "    if is_source(k_abs):\n",
        "        uncovered_map[k_abs] = sorted(set(int(x) for x in v))\n",
        "\n",
        "raw_observed: Dict[str, Dict[str, Dict[str, float]]] = json.loads(OBSERVED_JSON.read_text(encoding=\"utf-8\"))\n",
        "observed_outcomes: Dict[str, Dict[int, Dict[str, float]]] = {}\n",
        "for k, mapping in raw_observed.items():\n",
        "    k_abs = norm_abs(k)\n",
        "    if is_source(k_abs):\n",
        "        fixed = {}\n",
        "        for ln_str, meta in mapping.items():\n",
        "            try:\n",
        "                ln = int(ln_str)\n",
        "            except Exception:\n",
        "                continue\n",
        "            fixed[ln] = meta\n",
        "        observed_outcomes[k_abs] = fixed\n",
        "\n",
        "# half-hit 집합(라인은 int로)\n",
        "half_hit_map: Dict[str, Set[int]] = {}\n",
        "for file_abs, mapping in observed_outcomes.items():\n",
        "    halfs: Set[int] = set()\n",
        "    for ln, meta in mapping.items():\n",
        "        covered = int(meta.get(\"covered\", 0))\n",
        "        total   = int(meta.get(\"total\", 0))\n",
        "        if covered > 0 and covered < total:\n",
        "            halfs.add(ln)\n",
        "    if halfs:\n",
        "        half_hit_map[file_abs] = halfs\n",
        "\n",
        "# ---------------- 모킹 플랜 자동추론: 설정 ----------------\n",
        "# 모듈/심볼 카탈로그\n",
        "MOD_REQS = {\"requests\"}\n",
        "MOD_HTTPX = {\"httpx\"}\n",
        "MOD_TEMPORAL = {\"temporalio\"}\n",
        "MOD_ASYNCIO = {\"asyncio\"}\n",
        "MOD_TIME = {\"time\"}\n",
        "MOD_DATETIME = {\"datetime\"}\n",
        "MOD_OS = {\"os\"}\n",
        "MOD_SUBPROCESS = {\"subprocess\"}\n",
        "MOD_SYS = {\"sys\"}\n",
        "MOD_BUILTINS = {\"builtins\"}\n",
        "\n",
        "# 타깃 심볼 패턴\n",
        "SYM_ASYNCIO_RUN = {(\"asyncio\", \"run\")}\n",
        "SYM_TIME_SLEEP = {(\"time\", \"sleep\")}\n",
        "SYM_DATETIME_NOW = {(\"datetime\", \"datetime\", \"now\")}\n",
        "SYM_OS_ENVIRON = {(\"os\", \"environ\")}\n",
        "SYM_SYS_EXIT = {(\"sys\", \"exit\")}\n",
        "# Temporal common surfaces\n",
        "TEMPORAL_PREFIXES = (\n",
        "    \"temporalio.client.\", \"temporalio.worker.\", \"temporalio.workflow.\"\n",
        ")\n",
        "\n",
        "# ---------------- AST analysis ----------------\n",
        "class FunctionInfo:\n",
        "    def __init__(self, name: str, lineno: int):\n",
        "        self.name = name or \"<module>\"\n",
        "        self.lineno = lineno\n",
        "        self.branches: List[int] = []\n",
        "        self.defs: Dict[str, List[int]] = {}\n",
        "        self.uses: Dict[str, List[int]] = {}\n",
        "        self.exceptions: List[Tuple[str, int, dict]] = []\n",
        "        self.side_effect_calls: List[Tuple[str, int]] = []  # (kind, line)\n",
        "\n",
        "    def add_def(self, var: str, line: int):\n",
        "        self.defs.setdefault(var, []).append(line)\n",
        "\n",
        "    def add_use(self, var: str, line: int):\n",
        "        self.uses.setdefault(var, []).append(line)\n",
        "\n",
        "class ASTVisitor(ast.NodeVisitor):\n",
        "    \"\"\"임포트 별칭 추적 + 호출 qualname 복원으로 모킹 대상 자동 탐지 강화\"\"\"\n",
        "    def __init__(self, file_path: str):\n",
        "        self.file_path = file_path\n",
        "        self.stack: List[FunctionInfo] = []\n",
        "        self.funcs: List[FunctionInfo] = []\n",
        "        # 별칭 → 원본모듈/심볼 매핑\n",
        "        self.alias_to_module: Dict[str, str] = {}\n",
        "        self.symbol_to_module: Dict[str, str] = {}\n",
        "\n",
        "    def current(self) -> FunctionInfo:\n",
        "        if not self.stack:\n",
        "            if not self.funcs or self.funcs[0].name != \"<module>\":\n",
        "                fi = FunctionInfo(\"<module>\", 1)\n",
        "                self.funcs.insert(0, fi)\n",
        "            return self.funcs[0]\n",
        "        return self.stack[-1]\n",
        "\n",
        "    # ---- import tracking ----\n",
        "    def visit_Import(self, node: ast.Import):\n",
        "        for alias in node.names:\n",
        "            mod = alias.name  # e.g., \"requests\"\n",
        "            asname = alias.asname or mod.split(\".\")[0]\n",
        "            self.alias_to_module[asname] = mod\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_ImportFrom(self, node: ast.ImportFrom):\n",
        "        mod = node.module or \"\"\n",
        "        for alias in node.names:\n",
        "            asname = alias.asname or alias.name\n",
        "            # 심볼이지만 상위 모듈에 귀속\n",
        "            self.symbol_to_module[asname] = mod\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    # ---- function scopes ----\n",
        "    def visit_FunctionDef(self, node: ast.FunctionDef):\n",
        "        fi = FunctionInfo(node.name, node.lineno)\n",
        "        self.stack.append(fi)\n",
        "        self.generic_visit(node)\n",
        "        self.stack.pop()\n",
        "        self.funcs.append(fi)\n",
        "\n",
        "    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):\n",
        "        self.visit_FunctionDef(node)\n",
        "\n",
        "    # ---- branch-like points ----\n",
        "    def visit_If(self, node: ast.If):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_While(self, node: ast.While):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_For(self, node: ast.For):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_AsyncFor(self, node: ast.AsyncFor):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_With(self, node: ast.With):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_Try(self, node: ast.Try):\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.current().exceptions.append((\"try\", node.lineno, {}))\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_ExceptHandler(self, node: ast.ExceptHandler):\n",
        "        hint = {}\n",
        "        if node.type is not None:\n",
        "            typ = try_unparse(node.type) or getattr(getattr(node.type, \"id\", None), \"id\", None)\n",
        "            if typ:\n",
        "                hint[\"exception_type\"] = typ\n",
        "        self.current().branches.append(node.lineno)\n",
        "        self.current().exceptions.append((\"except\", node.lineno, hint))\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    # ---- exceptions ----\n",
        "    def visit_Raise(self, node: ast.Raise):\n",
        "        hint = {}\n",
        "        if node.exc is not None:\n",
        "            text = try_unparse(node.exc)\n",
        "            if text:\n",
        "                hint[\"expr\"] = text\n",
        "            if isinstance(node.exc, ast.Call):\n",
        "                if isinstance(node.exc.func, ast.Name):\n",
        "                    hint[\"exception_type\"] = node.exc.func.id\n",
        "                elif isinstance(node.exc.func, ast.Attribute):\n",
        "                    hint[\"exception_type\"] = node.exc.func.attr\n",
        "                if node.exc.args:\n",
        "                    a0 = node.exc.args[0]\n",
        "                    if isinstance(a0, ast.Constant) and isinstance(a0.value, str):\n",
        "                        hint[\"message_contains\"] = a0.value[:80]\n",
        "        self.current().exceptions.append((\"raise\", node.lineno, hint))\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_Assert(self, node: ast.Assert):\n",
        "        hint = {}\n",
        "        if node.msg and isinstance(node.msg, ast.Constant) and isinstance(node.msg.value, str):\n",
        "            hint[\"message_contains\"] = node.msg.value[:80]\n",
        "        self.current().exceptions.append((\"assert\", node.lineno, hint))\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    # ---- defs/uses ----\n",
        "    def visit_Name(self, node: ast.Name):\n",
        "        if isinstance(node.ctx, ast.Store):\n",
        "            self.current().add_def(node.id, node.lineno)\n",
        "        elif isinstance(node.ctx, ast.Load):\n",
        "            self.current().add_use(node.id, node.lineno)\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    # ---- helper: reconstruct dotted name ----\n",
        "    def _dotted_name(self, node: ast.AST) -> Optional[str]:\n",
        "        # Name → \"x\"\n",
        "        if isinstance(node, ast.Name):\n",
        "            name = node.id\n",
        "            # resolve alias/symbol to module if known\n",
        "            if name in self.alias_to_module:\n",
        "                return self.alias_to_module[name]\n",
        "            if name in self.symbol_to_module:\n",
        "                return f\"{self.symbol_to_module[name]}.{name.split('.')[-1]}\"\n",
        "            return name\n",
        "        # Attribute → \"<base>.<attr>\"\n",
        "        if isinstance(node, ast.Attribute):\n",
        "            base = self._dotted_name(node.value)\n",
        "            if base:\n",
        "                return f\"{base}.{node.attr}\"\n",
        "        # Call target might be ast.Call( func=Attribute(...) ) etc.\n",
        "        return None\n",
        "    # ---- side-effects heuristics (수정판) ----\n",
        "    def visit_Call(self, node: ast.Call):\n",
        "        qn = self._dotted_name(node.func) or \"\"\n",
        "\n",
        "        # builtins.open\n",
        "        if qn in (\"open\", \"builtins.open\"):\n",
        "            self.current().side_effect_calls.append((\"io_open\", node.lineno))\n",
        "\n",
        "        # requests.*, httpx.*\n",
        "        if any(qn.startswith(m + \".\") for m in MOD_REQS):\n",
        "            self.current().side_effect_calls.append((\"net_requests\", node.lineno))\n",
        "        if any(qn.startswith(m + \".\") for m in MOD_HTTPX):\n",
        "            self.current().side_effect_calls.append((\"net_httpx\", node.lineno))\n",
        "\n",
        "        # asyncio.run\n",
        "        if qn == \"asyncio.run\":\n",
        "            self.current().side_effect_calls.append((\"asyncio_run\", node.lineno))\n",
        "\n",
        "        # time.sleep\n",
        "        if qn == \"time.sleep\":\n",
        "            self.current().side_effect_calls.append((\"time_sleep\", node.lineno))\n",
        "\n",
        "        # datetime.datetime.now\n",
        "        if qn == \"datetime.datetime.now\":\n",
        "            self.current().side_effect_calls.append((\"datetime_now\", node.lineno))\n",
        "\n",
        "        # os.environ[...] / os.environ.get(...)\n",
        "        if qn.startswith(\"os.environ\"):\n",
        "            self.current().side_effect_calls.append((\"env_access\", node.lineno))\n",
        "\n",
        "        # subprocess.*\n",
        "        if any(qn.startswith(m + \".\") for m in MOD_SUBPROCESS):\n",
        "            self.current().side_effect_calls.append((\"subprocess\", node.lineno))\n",
        "\n",
        "        # sys.exit\n",
        "        if qn == \"sys.exit\":\n",
        "            self.current().side_effect_calls.append((\"sys_exit\", node.lineno))\n",
        "\n",
        "        # temporalio.*\n",
        "        if any(qn.startswith(pref) for pref in TEMPORAL_PREFIXES) or any(qn.startswith(m + \".\") for m in MOD_TEMPORAL):\n",
        "            kind = \"temporal_generic\"\n",
        "            if \".client.\" in qn:\n",
        "                kind = \"temporal_client\"\n",
        "            elif \".worker.\" in qn:\n",
        "                kind = \"temporal_worker\"\n",
        "            elif \".workflow.\" in qn:\n",
        "                kind = \"temporal_workflow\"\n",
        "            self.current().side_effect_calls.append((kind, node.lineno))\n",
        "\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_Attribute(self, node: ast.Attribute):\n",
        "        qn = self._dotted_name(node) or \"\"\n",
        "        # os.environ (속성 참조도 기록)\n",
        "        if qn.startswith(\"os.environ\"):\n",
        "            self.current().side_effect_calls.append((\"env_access\", node.lineno))\n",
        "        self.generic_visit(node)\n",
        "\n",
        "# ---------------- collect candidate files ----------------\n",
        "candidate_files: List[str] = sorted(set([\n",
        "    *uncovered_map.keys(),\n",
        "    *observed_outcomes.keys(),\n",
        "]))\n",
        "candidate_files = [fp for fp in candidate_files if is_source(fp)]\n",
        "\n",
        "# ---------------- per file AST → materials ----------------\n",
        "file_infos: Dict[Tuple[str, str], Dict[str, List]] = {}\n",
        "\n",
        "for file_abs in candidate_files:\n",
        "    file_path = Path(file_abs)\n",
        "    try:\n",
        "        source = file_path.read_text(encoding=\"utf-8\")\n",
        "        tree = ast.parse(source)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ AST parse failed for {rel_from_proj(file_abs)}: {e}\")\n",
        "        continue\n",
        "\n",
        "    visitor = ASTVisitor(rel_from_proj(file_abs))\n",
        "    visitor.visit(tree)\n",
        "\n",
        "    miss_lines: Set[int] = set(uncovered_map.get(file_abs, []))\n",
        "    half_lines: Set[int] = half_hit_map.get(file_abs, set())\n",
        "\n",
        "    for fi in visitor.funcs:\n",
        "        # ---- 분기 필터: 미커버/half-hit 포함 라인만\n",
        "        tb = sorted([ln for ln in fi.branches if (ln in miss_lines or ln in half_lines)])\n",
        "\n",
        "        # ---- Def-Use 페어\n",
        "        tu_pairs: List[Tuple[str, int, int]] = []\n",
        "        for var, defs in fi.defs.items():\n",
        "            uses = sorted(fi.uses.get(var, []))\n",
        "            defs_sorted = sorted(defs)\n",
        "            for u in uses:\n",
        "                if u not in miss_lines:\n",
        "                    continue\n",
        "                d_le = [d for d in defs_sorted if d <= u]\n",
        "                if not d_le:\n",
        "                    continue\n",
        "                d = max(d_le)\n",
        "                if any((d < d2 < u) for d2 in defs_sorted if d2 != d):\n",
        "                    continue\n",
        "                if (u - d) > 40:\n",
        "                    continue\n",
        "                tu_pairs.append((var, d, u))\n",
        "        tu = sorted(tu_pairs, key=lambda x: (x[2], x[1], x[0]))\n",
        "\n",
        "        # ---- 예외: 미커버 포함만\n",
        "        te = sorted(\n",
        "            [(kind, line, hint) for (kind, line, hint) in fi.exceptions if line in miss_lines],\n",
        "            key=lambda x: (x[1], x[0])\n",
        "        )\n",
        "\n",
        "        # ---- side-effects → mock 필요성/종류\n",
        "        mock_kinds = sorted(set(k for (k, _) in fi.side_effect_calls))\n",
        "        needs_mock = bool(mock_kinds)\n",
        "\n",
        "        if tb or tu or te:\n",
        "            file_infos[(rel_from_proj(file_abs), fi.name)] = {\n",
        "                \"branches\": tb,\n",
        "                \"def_uses\": tu,\n",
        "                \"exceptions\": te,\n",
        "                \"func_lineno\": fi.lineno,\n",
        "                \"needs_mock\": needs_mock,\n",
        "                \"mock_kinds\": mock_kinds,\n",
        "            }\n",
        "\n",
        "# ---------------- goal builders ----------------\n",
        "MAX_NEAR_GAP = 8\n",
        "\n",
        "# ==== [새 설정] 알고리즘1 하이퍼파라미터 ====\n",
        "# coverage gain 가중치 (분기/Def-Use/예외) — 합이 1이 되도록\n",
        "ALPHA_BRANCH = 0.45   # α\n",
        "BETA_DU      = 0.25   # β\n",
        "GAMMA_EXC    = 0.30   # γ\n",
        "\n",
        "# generation cost 가중치 (상수/문맥/타겟수) — 합이 1이 되도록\n",
        "LAMBDA_1_CONST   = 0.20  # λ1 · 1.0\n",
        "LAMBDA_2_CONTEXT = 0.60  # λ2 · |Context_g|\n",
        "LAMBDA_3_TARGETS = 0.20  # λ3 · |T_g|\n",
        "\n",
        "# 예산(비용 단위). 예: 50이면 합산 cost가 50을 넘지 않는 선에서 선택\n",
        "BUDGET_B = 50.0\n",
        "\n",
        "# 중복(겹침) 허용 임계값 θ — 후보 g의 타깃 라인 중\n",
        "# 기존에 선택된 목표들과 겹치는 비율이 θ 이상이면 제외\n",
        "OVERLAP_THETA = 0.50  # 0.0(허용적) ~ 1.0(강한 배제)\n",
        "\n",
        "# ---- coverage gain / cost / score ----\n",
        "def coverage_gain_structural(b_cnt: int, du_cnt: int, exc_cnt: int) -> float:\n",
        "    \"\"\"rel(g) = α|B_g| + β|D_g| + γ|E_g|\"\"\"\n",
        "    return ALPHA_BRANCH * b_cnt + BETA_DU * du_cnt + GAMMA_EXC * exc_cnt\n",
        "\n",
        "def coverage_gain_total(target_lines: Set[int], b_cnt: int, du_cnt: int, exc_cnt: int) -> float:\n",
        "    \"\"\"gain(g) = |T_g| + rel(g)\"\"\"\n",
        "    return float(len(target_lines)) + coverage_gain_structural(b_cnt, du_cnt, exc_cnt)\n",
        "\n",
        "def generation_cost(context_size: int, target_count: int) -> float:\n",
        "    \"\"\"cost(g) = λ1*1.0 + λ2*|Context_g| + λ3*|T_g|\"\"\"\n",
        "    return (LAMBDA_1_CONST * 1.0) + (LAMBDA_2_CONTEXT * float(context_size)) + (LAMBDA_3_TARGETS * float(target_count))\n",
        "\n",
        "def compute_context_size(fi: FunctionInfo) -> int:\n",
        "    \"\"\"|Context_g| = 함수 내 정의/사용 라인의 총합(유니크)\"\"\"\n",
        "    def_lines = {ln for lines in fi.defs.values() for ln in lines}\n",
        "    use_lines = {ln for lines in fi.uses.values() for ln in lines}\n",
        "    return len(def_lines | use_lines)\n",
        "\n",
        "# ---------------- per file AST → materials (보강: context size 저장) ----------------\n",
        "file_infos: Dict[Tuple[str, str], Dict[str, List]] = {}\n",
        "\n",
        "for file_abs in candidate_files:\n",
        "    file_path = Path(file_abs)\n",
        "    try:\n",
        "        source = file_path.read_text(encoding=\"utf-8\")\n",
        "        tree = ast.parse(source)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ AST parse failed for {rel_from_proj(file_abs)}: {e}\")\n",
        "        continue\n",
        "\n",
        "    visitor = ASTVisitor(rel_from_proj(file_abs))\n",
        "    visitor.visit(tree)\n",
        "\n",
        "    miss_lines: Set[int] = set(uncovered_map.get(file_abs, []))\n",
        "    half_lines: Set[int] = half_hit_map.get(file_abs, set())\n",
        "\n",
        "    for fi in visitor.funcs:\n",
        "        # ---- 분기 필터: 미커버/half-hit 포함 라인만\n",
        "        tb = sorted([ln for ln in fi.branches if (ln in miss_lines or ln in half_lines)])\n",
        "\n",
        "        # ---- Def-Use 페어\n",
        "        tu_pairs: List[Tuple[str, int, int]] = []\n",
        "        for var, defs in fi.defs.items():\n",
        "            uses = sorted(fi.uses.get(var, []))\n",
        "            defs_sorted = sorted(defs)\n",
        "            for u in uses:\n",
        "                if u not in miss_lines:\n",
        "                    continue\n",
        "                d_le = [d for d in defs_sorted if d <= u]\n",
        "                if not d_le:\n",
        "                    continue\n",
        "                d = max(d_le)\n",
        "                if any((d < d2 < u) for d2 in defs_sorted if d2 != d):\n",
        "                    continue\n",
        "                if (u - d) > 40:\n",
        "                    continue\n",
        "                tu_pairs.append((var, d, u))\n",
        "        tu = sorted(tu_pairs, key=lambda x: (x[2], x[1], x[0]))\n",
        "\n",
        "        # ---- 예외: 미커버 포함만\n",
        "        te = sorted(\n",
        "            [(kind, line, hint) for (kind, line, hint) in fi.exceptions if line in miss_lines],\n",
        "            key=lambda x: (x[1], x[0])\n",
        "        )\n",
        "\n",
        "        # ---- side-effects → mock 종류(메타정보로 유지)\n",
        "        mock_kinds = sorted(set(k for (k, _) in fi.side_effect_calls))\n",
        "        needs_mock = bool(mock_kinds)\n",
        "\n",
        "        # ---- 문맥 크기(|Context_g|) 저장\n",
        "        ctx_size = compute_context_size(fi)\n",
        "\n",
        "        if tb or tu or te:\n",
        "            file_infos[(rel_from_proj(file_abs), fi.name)] = {\n",
        "                \"branches\": tb,\n",
        "                \"def_uses\": tu,\n",
        "                \"exceptions\": te,\n",
        "                \"func_lineno\": fi.lineno,\n",
        "                \"needs_mock\": needs_mock,\n",
        "                \"mock_kinds\": mock_kinds,\n",
        "                \"context_size\": ctx_size,\n",
        "            }\n",
        "\n",
        "# ---------------- goal builders (후보 생성) ----------------\n",
        "def make_goal(file_rel: str, func_name: str, func_lineno: int,\n",
        "              branches: List[int], def_uses: List[Tuple[str,int,int]],\n",
        "              exceptions: List[Tuple[str,int,dict]], needs_mock: bool, mock_kinds: List[str],\n",
        "              context_size: int) -> dict:\n",
        "    # T_g\n",
        "    target_lines: Set[int] = set(branches)\n",
        "    for _, d, u in def_uses:\n",
        "        target_lines.update([d, u])\n",
        "    for _, line, _ in exceptions:\n",
        "        target_lines.add(line)\n",
        "\n",
        "    # 구조 수량\n",
        "    b_cnt = len(branches)\n",
        "    du_cnt = len(def_uses)\n",
        "    exc_cnt = len(exceptions)\n",
        "\n",
        "    # 이득/비용/점수\n",
        "    gain = coverage_gain_total(target_lines, b_cnt, du_cnt, exc_cnt)\n",
        "    cost = generation_cost(context_size, len(target_lines))\n",
        "    score = (gain / cost) if cost > 0 else 0.0\n",
        "\n",
        "    # half-hit 존재 여부(힌트)\n",
        "    file_abs = norm_abs(file_rel)\n",
        "    need_two = any(ln in half_hit_map.get(file_abs, set()) for ln in branches)\n",
        "\n",
        "    exc_hints = []\n",
        "    for kind, line, hint in exceptions:\n",
        "        h = {\"kind\": kind, \"line\": line}\n",
        "        h.update(hint or {})\n",
        "        exc_hints.append(h)\n",
        "\n",
        "    return {\n",
        "        \"id\": None,\n",
        "        \"file\": file_rel,\n",
        "        \"function\": {\"name\": func_name, \"lineno\": func_lineno},\n",
        "        \"components\": {\n",
        "            \"branches\": [{\"line\": ln} for ln in branches],\n",
        "            \"def_uses\": [{\"var\": var, \"def_line\": d, \"use_line\": u} for var, d, u in def_uses],\n",
        "            \"exceptions\": exc_hints,\n",
        "        },\n",
        "        \"target_lines\": sorted(target_lines),\n",
        "        \"hints\": {\n",
        "            \"need_two_sides_for_half_hit\": need_two,\n",
        "            \"needs_mock\": needs_mock,\n",
        "            \"mock_plan\": mock_kinds,\n",
        "            \"exception_hint\": exc_hints,\n",
        "        },\n",
        "        \"coverage_gain\": round(gain, 6),\n",
        "        \"generation_cost\": round(cost, 6),\n",
        "        \"score\": round(score, 6),\n",
        "        \"context_size\": context_size,\n",
        "    }\n",
        "\n",
        "# 후보 생성\n",
        "candidates: List[dict] = []\n",
        "\n",
        "for (file_rel, func_name), info in file_infos.items():\n",
        "    func_lineno = info[\"func_lineno\"]\n",
        "    tb = info[\"branches\"]\n",
        "    tu = info[\"def_uses\"]\n",
        "    te = info[\"exceptions\"]\n",
        "    needs_mock = info[\"needs_mock\"]\n",
        "    mock_kinds = info[\"mock_kinds\"]\n",
        "    ctx_size = info[\"context_size\"]\n",
        "\n",
        "    # 단일\n",
        "    for b in tb:\n",
        "        candidates.append(make_goal(file_rel, func_name, func_lineno, [b], [], [], needs_mock, mock_kinds, ctx_size))\n",
        "    for var, d, u in tu:\n",
        "        candidates.append(make_goal(file_rel, func_name, func_lineno, [], [(var, d, u)], [], needs_mock, mock_kinds, ctx_size))\n",
        "    for kind, line, hint in te:\n",
        "        candidates.append(make_goal(file_rel, func_name, func_lineno, [], [], [(kind, line, hint)], needs_mock, mock_kinds, ctx_size))\n",
        "\n",
        "    # 2-개 조합 (근접 연결)\n",
        "    for b in tb:\n",
        "        for var, d, u in tu:\n",
        "            if max(b, u) - min(b, d) <= MAX_NEAR_GAP:\n",
        "                candidates.append(make_goal(file_rel, func_name, func_lineno, [b], [(var, d, u)], [], needs_mock, mock_kinds, ctx_size))\n",
        "    for b in tb:\n",
        "        for kind, line, hint in te:\n",
        "            if abs(b - line) <= MAX_NEAR_GAP:\n",
        "                candidates.append(make_goal(file_rel, func_name, func_lineno, [b], [], [(kind, line, hint)], needs_mock, mock_kinds, ctx_size))\n",
        "    for var, d, u in tu:\n",
        "        for kind, line, hint in te:\n",
        "            if max(u, line) - min(d, line) <= MAX_NEAR_GAP:\n",
        "                candidates.append(make_goal(file_rel, func_name, func_lineno, [], [(var, d, u)], [(kind, line, hint)], needs_mock, mock_kinds, ctx_size))\n",
        "\n",
        "    # 3-개 조합 (근접 연결)\n",
        "    for b in tb:\n",
        "        for var, d, u in tu:\n",
        "            for kind, line, hint in te:\n",
        "                lines = [b, d, u, line]\n",
        "                if max(lines) - min(lines) <= MAX_NEAR_GAP:\n",
        "                    candidates.append(make_goal(file_rel, func_name, func_lineno, [b], [(var, d, u)], [(kind, line, hint)], needs_mock, mock_kinds, ctx_size))\n",
        "\n",
        "# ---------------- 후보 중복 제거(동등 구성은 score 높은 것만) ----------------\n",
        "def goal_key(g):\n",
        "    comps = g[\"components\"]\n",
        "    return (\n",
        "        tuple(sorted(b[\"line\"] for b in comps[\"branches\"])),\n",
        "        tuple(sorted((du[\"var\"], du[\"def_line\"], du[\"use_line\"]) for du in comps[\"def_uses\"])),\n",
        "        tuple(sorted((ex.get(\"kind\"), ex.get(\"line\")) for ex in comps[\"exceptions\"])),\n",
        "        g[\"file\"],\n",
        "        g[\"function\"][\"name\"],\n",
        "    )\n",
        "\n",
        "unique_map = {}\n",
        "for g in candidates:\n",
        "    k = goal_key(g)\n",
        "    if k not in unique_map or g[\"score\"] > unique_map[k][\"score\"]:\n",
        "        unique_map[k] = g\n",
        "\n",
        "candidates = list(unique_map.values())\n",
        "\n",
        "# ---------------- 예산 기반 선택 (Algorithm 1: lines 12~15) ----------------\n",
        "def overlap_ratio(g: dict, selected: List[dict]) -> float:\n",
        "    \"\"\"overlap(g, selected) = |Tg ∩ (⋃Ts)| / |Tg|\"\"\"\n",
        "    if not selected:\n",
        "        return 0.0\n",
        "    tg = set(g[\"target_lines\"])\n",
        "    if not tg:\n",
        "        return 1.0  # 빈 목표는 의미 없으므로 겹침 100% 취급\n",
        "    union_sel = set()\n",
        "    for s in selected:\n",
        "        union_sel.update(s[\"target_lines\"])\n",
        "    inter = tg & union_sel\n",
        "    return len(inter) / len(tg)\n",
        "\n",
        "# 점수 내림차순(동점이면 gain 큰 순, target 작을수록 우선)\n",
        "candidates.sort(key=lambda x: (-x[\"score\"], -x[\"coverage_gain\"], x[\"generation_cost\"], x[\"file\"], x[\"function\"][\"name\"]))\n",
        "\n",
        "selected: List[dict] = []\n",
        "budget = float(BUDGET_B)\n",
        "\n",
        "rem = candidates[:]  # 남은 후보\n",
        "while budget > 0.0 and rem:\n",
        "    g = rem.pop(0)  # 최고 점수\n",
        "    if g[\"score\"] <= 0.0:\n",
        "        continue\n",
        "    if overlap_ratio(g, selected) < OVERLAP_THETA and g[\"generation_cost\"] <= budget:\n",
        "        selected.append(g)\n",
        "        budget -= g[\"generation_cost\"]\n",
        "\n",
        "# ---------------- id 부여 및 저장 ----------------\n",
        "for i, g in enumerate(selected, 1):\n",
        "    g[\"id\"] = f\"{i:04d}\"\n",
        "\n",
        "# 상세 원본(선택 결과)\n",
        "(ART_DIR / \"goals_raw.json\").write_text(\n",
        "    json.dumps(selected, indent=2, ensure_ascii=False),\n",
        "    encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "# 랭크 출력(이득 기준 정렬 유지)\n",
        "ranked = [\n",
        "    {\n",
        "        \"id\": g[\"id\"],\n",
        "        \"file\": g[\"file\"],\n",
        "        \"function\": g[\"function\"],\n",
        "        \"components\": g[\"components\"],\n",
        "        \"target_lines\": g[\"target_lines\"],\n",
        "        \"coverage_gain\": round(float(g[\"coverage_gain\"]), 3),\n",
        "        \"generation_cost\": round(float(g[\"generation_cost\"]), 3),\n",
        "        \"score\": round(float(g[\"score\"]), 3),\n",
        "        \"hints\": g[\"hints\"],\n",
        "        \"context_size\": g[\"context_size\"],\n",
        "    }\n",
        "    for g in selected\n",
        "]\n",
        "(ART_DIR / \"goals_ranked.json\").write_text(\n",
        "    json.dumps(ranked, indent=2, ensure_ascii=False),\n",
        "    encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "print(f\"✅ 복합 목표 생성 완료: {len(selected)}개 선택 (예산 B={BUDGET_B}, θ={OVERLAP_THETA})\")\n",
        "print(\" - 입력: uncovered_map_base.json, observed_outcomes_base.json\")\n",
        "print(\" - 저장: goals_raw.json, goals_ranked.json\")\n",
        "print(f\" - 후보 총수: {len(candidates)} / 선택 총비용: {round(BUDGET_B - budget, 3)} / 남은 예산: {round(budget, 3)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "q3TIL3otgCzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d61e49da-db00-4b37-b54b-af49d6f15974"
      },
      "id": "q3TIL3otgCzm",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 복합 목표 생성 완료: 10개 선택 (예산 B=50.0, θ=0.5)\n",
            " - 입력: uncovered_map_base.json, observed_outcomes_base.json\n",
            " - 저장: goals_raw.json, goals_ranked.json\n",
            " - 후보 총수: 94 / 선택 총비용: 44.8 / 남은 예산: 5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-3) LLM 프롬프트 생성 – 시스템/사용자 지시부 이원화(우선순위/식별자 포함)\n",
        "import json, re\n",
        "from pathlib import Path\n",
        "\n",
        "PROJ_PATH = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ_PATH / \"run_artifacts\" / \"run1\"\n",
        "GOALS_FILE = ART_DIR / \"goals_ranked.json\"\n",
        "LLM_PROMPTS_PATH = ART_DIR / \"llm_prompts.jsonl\"\n",
        "\n",
        "assert GOALS_FILE.exists(), \"goals_ranked.json이 없습니다. 3-2 단계를 먼저 실행하세요.\"\n",
        "goals = json.loads(GOALS_FILE.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "def to_mod_name(file_rel: str) -> str:\n",
        "    s = file_rel.replace(\"\\\\\", \"/\")\n",
        "    if s.endswith(\".py\"):\n",
        "        s = s[:-3]\n",
        "    return s.replace(\"/\", \".\")\n",
        "\n",
        "def suggest_filename(goal):\n",
        "    mod = to_mod_name(goal[\"file\"]).split(\".\")[-1]\n",
        "    func = goal[\"function\"][\"name\"]\n",
        "    safe = lambda x: re.sub(r\"[^a-zA-Z0-9_]+\", \"_\", str(x))\n",
        "    return f\"test_gen_{safe(goal['id'])}_{safe(mod)}_{safe(func)}.py\"\n",
        "\n",
        "# ---------------- 시스템 지시부 (역할/출력/제약 고정) ----------------\n",
        "SYSTEM_INSTR = (\n",
        "    \"역할: 당신은 주어진 목표(분기/정의-사용/예외)를 실제로 실행하는 PyTest 테스트 코드를 생성하는 '테스트 생성기'입니다.\\n\"\n",
        "    \"출력 형식: 마크다운/주석 없이 오직 하나의 JSON 객체로만 응답하세요.\\n\"\n",
        "    \"출력 스키마:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"filename\": \"test_*.py\",\\n'\n",
        "    '  \"tests\": [\\n'\n",
        "    '    {\"name\": \"test_*\", \"code\": \"<pytest 테스트 파일 전체 코드 문자열>\"}\\n'\n",
        "    \"  ]\\n\"\n",
        "    \"}\\n\"\n",
        "    \"행동 제약(엄격):\\n\"\n",
        "    \"• 원본 코드는 수정 금지, 테스트 파일만 작성\\n\"\n",
        "    \"• importlib로 모듈 로드 후 getattr로 심볼 접근\\n\"\n",
        "    \"  └ 심볼이 '정말로' 없을 때만 다음 가드 패턴으로 skip 허용:\\n\"\n",
        "    \"     >>> tgt = getattr(mod, 'symbol', None)\\n\"\n",
        "    \"     >>> if tgt is None:\\n\"\n",
        "    \"     >>>     pytest.skip('symbol missing')\\n\"\n",
        "    \"  └ 위 가드 없이 호출되는 모든 skip은 무조건 금지(검증기에서 즉시 탈락)\\n\"\n",
        "    \"• 각 테스트는 최소 1개 이상의 assert 또는 pytest.raises(...)를 포함해야 함(없으면 탈락)\\n\"\n",
        "    \"• 파일/네트워크/시간/환경/비동기 루프/Temporal 등 외부 접근은 mock/monkeypatch로 대체\\n\"\n",
        "    \"• 분기는 양 경로를 모두 검증(half-hit 지시 시 독립 테스트 2개)\\n\"\n",
        "    \"• def-use는 (def_line→use_line) 효과를 관측 가능한 assert로 입증\\n\"\n",
        "    \"• 예외 경로는 with pytest.raises(...)로 타입/가능하면 메시지를 검증\\n\"\n",
        "    \"• 전역 상태 잔존 금지, 불필요한 광범위 try/except 금지, 무관한 assert 금지\\n\"\n",
        "    \"• 테스트 이름에 타격 라인 포함: `..._hits_L<line>` 형태 권장\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "# 우선순위 기준: score가 있으면 score, 없으면 coverage_gain\n",
        "def priority_of(g: dict) -> float:\n",
        "    return float(g.get(\"score\", g.get(\"coverage_gain\", 0.0)))\n",
        "\n",
        "# rank를 부여(이미 goals_ranked.json이 정렬되어 있어도 안전하게 재정렬)\n",
        "goals_sorted = sorted(goals, key=lambda x: (-priority_of(x), -float(x.get(\"coverage_gain\", 0.0))))\n",
        "\n",
        "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
        "with LLM_PROMPTS_PATH.open(\"w\", encoding=\"utf-8\") as outf:\n",
        "    for rank, goal in enumerate(goals_sorted, start=1):\n",
        "        module_name = to_mod_name(goal[\"file\"])\n",
        "        suggested = suggest_filename(goal)\n",
        "\n",
        "        comps = goal.get(\"components\", {}) or {}\n",
        "        hints = goal.get(\"hints\", {}) or {}\n",
        "        mock_plan = hints.get(\"mock_plan\", []) or []\n",
        "        need_two  = bool(hints.get(\"need_two_sides_for_half_hit\", False))\n",
        "\n",
        "        # ---------------- 사용자 지시부 (실행 경로/검증 대상 명세) ----------------\n",
        "        USER_PAYLOAD = {\n",
        "            \"schema_version\": \"v1\",\n",
        "            \"identifier\": {\n",
        "                \"id\": goal[\"id\"],\n",
        "                \"rank\": rank,\n",
        "                \"priority\": priority_of(goal),           # 실행 단계에서 동적 우선순위로 활용\n",
        "                \"basis\": \"score\" if \"score\" in goal else \"coverage_gain\"\n",
        "            },\n",
        "            \"project\": {\n",
        "                \"root\": str(PROJ_PATH),\n",
        "                \"module\": module_name\n",
        "            },\n",
        "            \"goal\": {\n",
        "                \"file\": goal[\"file\"],\n",
        "                \"function\": goal[\"function\"],             # {\"name\": ..., \"lineno\": ...}\n",
        "                \"components\": {\n",
        "                    \"branches\": comps.get(\"branches\", []),\n",
        "                    \"def_uses\": comps.get(\"def_uses\", []),\n",
        "                    \"exceptions\": comps.get(\"exceptions\", [])\n",
        "                },\n",
        "                \"target_lines\": goal.get(\"target_lines\", [])\n",
        "            },\n",
        "            \"constraints\": {\n",
        "                \"filename_suggestion\": suggested,\n",
        "                \"import_policy\": {\n",
        "                    \"strategy\": \"importlib_only\",\n",
        "                    \"on_missing\": \"pytest.skip\"           # 속성이 없을 때만 skip 허용\n",
        "                },\n",
        "                \"isolation_policy\": {\n",
        "                    \"no_fs_no_net\": True,\n",
        "                    \"patch_time\": True,\n",
        "                    \"forbid_asyncio_run\": True,\n",
        "                    \"forbid_temporal_real_runs\": True,\n",
        "                    \"patch_env\": True\n",
        "                },\n",
        "                \"execution_contract\": {\n",
        "                    \"must_hit_at_least_n_target_lines\": 1,\n",
        "                    \"require_two_tests_for_half_hit\": need_two,\n",
        "                    \"test_name_must_include_hit_lines\": True\n",
        "                },\n",
        "                \"assert_policy\": {\n",
        "                    \"prefer_pytest_raises\": True,\n",
        "                    \"prefer_explicit_asserts\": True,\n",
        "                    \"no_unrelated_asserts\": True\n",
        "                }\n",
        "            },\n",
        "            \"hints\": {\n",
        "                \"needs_mock\": bool(hints.get(\"needs_mock\", False) or mock_plan),\n",
        "                \"mock_plan\": mock_plan,                    # [\"io_open\",\"net_requests\",\"env_access\",\"time_sleep\",\"datetime_now\",...]\n",
        "                \"exception_hint\": comps.get(\"exceptions\", [])\n",
        "            },\n",
        "            # 테스트 스캐폴딩(생성 순서 가이드만 제공)\n",
        "            \"scaffolding\": [\n",
        "                \"1) importlib로 모듈 로드, getattr로 심볼 확보(없으면만 skip).\",\n",
        "                \"2) 목표 경로(분기/def-use/예외)를 만족하는 입력 벡터 구성.\",\n",
        "                \"3) 외부 의존은 monkeypatch/더블로 대체.\",\n",
        "                \"4) 호출로 target_lines를 실제 타격.\",\n",
        "                \"5) 관측 가능한 assert 작성(반환/상태/호출/예외).\",\n",
        "                \"6) 테스트 이름에 hits_L<line> 포함.\"\n",
        "                \"7) 예시: tgt = getattr(mod, 'symbol', None);  if tgt is None: pytest.skip('symbol missing')\"\n",
        "            ],\n",
        "            # 모델에게 필요한 최소 지시만 남겨 군더더기 제거\n",
        "            \"instructions\": [\n",
        "                \"오직 지정된 JSON 스키마만 반환하세요.\",\n",
        "                \"각 테스트는 target_lines 중 최소 1줄을 실행해야 하며, 분기는 양 경로를 검증하세요.\",\n",
        "                \"def-use는 (def_line→use_line)의 효과를 관측 가능하게 검증하고, 예외는 타입/메시지를 검증하세요.\",\n",
        "                \"외부 접근은 모두 mock/monkeypatch로 대체하세요.\",\n",
        "                \"각 테스트에 최소 1개 이상의 assert 또는 pytest.raises(...)를 반드시 포함하세요.\",\n",
        "                \"pytest.skip()는 심볼이 없는 경우의 '가드형' 패턴에서만 허용되며, 그 외 사용 시 테스트는 거부됩니다.\"\n",
        "                ]\n",
        "        }\n",
        "\n",
        "        record = {\n",
        "            \"meta\": {\n",
        "                \"id\": goal[\"id\"],\n",
        "                \"rank\": rank,\n",
        "                \"priority\": USER_PAYLOAD[\"identifier\"][\"priority\"],\n",
        "                \"priority_basis\": USER_PAYLOAD[\"identifier\"][\"basis\"],\n",
        "                \"file\": goal[\"file\"],\n",
        "                \"function\": goal[\"function\"][\"name\"],\n",
        "                \"coverage_gain\": float(goal.get(\"coverage_gain\", 0.0)),\n",
        "                \"score\": float(goal.get(\"score\", USER_PAYLOAD[\"identifier\"][\"priority\"])),\n",
        "                \"suggested_filename\": suggested,\n",
        "                \"module\": module_name\n",
        "            },\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "                {\"role\": \"user\", \"content\": json.dumps(USER_PAYLOAD, ensure_ascii=False, indent=2)}\n",
        "            ]\n",
        "        }\n",
        "        outf.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(f\"✅ LLM 프롬프트 생성 완료 → {LLM_PROMPTS_PATH}\")\n",
        "print(\"   - 총 목표 수:\", len(goals_sorted))\n",
        "print(\"   - 최상위 우선순위 목표 ID:\", goals_sorted and goals_sorted[0].get(\"id\"))\n",
        "print(\"   - 예시 파일명:\", goals_sorted and suggest_filename(goals_sorted[0]))\n"
      ],
      "metadata": {
        "id": "dI-iQnUDhBwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3a2ac8-2edf-4084-b4e3-3450d8e06989"
      },
      "id": "dI-iQnUDhBwy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM 프롬프트 생성 완료 → /content/money-transfer-project-template-python/run_artifacts/run1/llm_prompts.jsonl\n",
            "   - 총 목표 수: 10\n",
            "   - 최상위 우선순위 목표 ID: 0001\n",
            "   - 예시 파일명: test_gen_0001_banking_service_deposit.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-4) 테스트 코드 생성 – 스키마/구조/최소 실행 요건 검증 후 저장\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import ast\n",
        "from pathlib import Path\n",
        "import httpx\n",
        "import backoff\n",
        "from openai import OpenAI, APIError, RateLimitError, APIConnectionError\n",
        "\n",
        "# ---------- 경로 설정 ----------\n",
        "ART_DIR = Path(PROJ) / \"run_artifacts\" / \"run1\"\n",
        "LLM_PROMPTS_PATH = ART_DIR / \"llm_prompts.jsonl\"\n",
        "GEN_DIR = Path(PROJ) / \"generated_tests\"\n",
        "RAW_DIR = ART_DIR / \"_raw\"\n",
        "ERR_DIR = ART_DIR / \"_errors\"\n",
        "GEN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ERR_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- OpenAI 클라이언트 ----------\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY가 설정되지 않았습니다. 3-0 단계에서 .env를 로드했는지 확인하세요.\")\n",
        "\n",
        "http_client = httpx.Client(\n",
        "    timeout=180.0,\n",
        "    follow_redirects=True,\n",
        "    limits=httpx.Limits(max_connections=1, max_keepalive_connections=0),\n",
        "    transport=httpx.HTTPTransport(retries=5),\n",
        ")\n",
        "client = OpenAI(\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    base_url=\"https://api.openai.com/v1\",\n",
        "    http_client=http_client,\n",
        ")\n",
        "\n",
        "# ---------- 유틸 ----------\n",
        "_slug_re = re.compile(r\"[^a-z0-9_]+\")\n",
        "def slugify(s: str, maxlen: int = 40) -> str:\n",
        "    s = s.lower().strip().replace(\"-\", \"_\").replace(\" \", \"_\")\n",
        "    s = _slug_re.sub(\"_\", s)\n",
        "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
        "    return s[:maxlen] or \"t\"\n",
        "\n",
        "def strip_fences(s: str) -> str:\n",
        "    s = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", s.strip())\n",
        "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def ensure_unique_path(base: Path) -> Path:\n",
        "    p = base\n",
        "    i = 2\n",
        "    while p.exists():\n",
        "        p = base.with_name(f\"{base.stem}_{i}{base.suffix}\")\n",
        "        i += 1\n",
        "    return p\n",
        "\n",
        "def write_error(goal_id: str, kind: str, payload: dict, idx: int | None = None):\n",
        "    tag = f\"goal_{goal_id}_{kind}\" if idx is None else f\"goal_{goal_id}_t{idx}_{kind}\"\n",
        "    (ERR_DIR / f\"{tag}.json\").write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# ---------- 보정기: runner 제거 ----------\n",
        "def sanitize_test_code(code: str) -> str:\n",
        "    \"\"\"\n",
        "    테스트 파일 안의 runner 호출 제거:\n",
        "      - if __name__ == \"__main__\": ... pytest.main()/unittest.main()\n",
        "      - 파일 어디든 있는 pytest.main(...), unittest.main(...)\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        re.compile(r\"(?ms)^\\s*if\\s+__name__\\s*==\\s*['\\\"]__main__['\\\"]\\s*:\\s*\\n(?:\\s+.*\\n?)+$\"),\n",
        "        re.compile(r\"(?m)^\\s*pytest\\.main\\s*\\(.*?\\)\\s*$\"),\n",
        "        re.compile(r\"(?m)^\\s*unittest\\.main\\s*\\(.*?\\)\\s*$\"),\n",
        "    ]\n",
        "    new = code\n",
        "    for pat in patterns:\n",
        "        new = pat.sub(\"\", new)\n",
        "    return new.strip() + \"\\n\"\n",
        "\n",
        "# ---------- 검증 로직 ----------\n",
        "RE_IMPORTLIB = re.compile(r\"\\bimportlib\\.import_module\\s*\\(\")\n",
        "RE_PYTEST_RAISES = re.compile(r\"\\bpytest\\.raises\\s*\\(\")\n",
        "\n",
        "def validate_json_schema(result: dict) -> tuple[bool, list[str]]:\n",
        "    reasons = []\n",
        "    if not isinstance(result, dict):\n",
        "        return False, [\"not_a_json_object\"]\n",
        "    if \"tests\" not in result:\n",
        "        reasons.append(\"missing_tests\")\n",
        "    else:\n",
        "        if not isinstance(result[\"tests\"], list) or len(result[\"tests\"]) == 0:\n",
        "            reasons.append(\"tests_empty_or_not_list\")\n",
        "        else:\n",
        "            for i, t in enumerate(result[\"tests\"], start=1):\n",
        "                if not isinstance(t, dict):\n",
        "                    reasons.append(f\"test_{i}_not_object\"); continue\n",
        "                if \"code\" not in t:\n",
        "                    reasons.append(f\"test_{i}_missing_code\")\n",
        "                if \"name\" not in t:\n",
        "                    reasons.append(f\"test_{i}_missing_name\")\n",
        "    if \"filename\" in result:\n",
        "        fn = str(result[\"filename\"])\n",
        "        if not fn.endswith(\".py\"):\n",
        "            reasons.append(\"filename_not_py\")\n",
        "    return (len(reasons) == 0), reasons\n",
        "\n",
        "def parse_ast_or_error(code: str):\n",
        "    try:\n",
        "        return ast.parse(code), None\n",
        "    except SyntaxError as e:\n",
        "        return None, f\"syntax_error:{e.msg}@L{e.lineno}\"\n",
        "\n",
        "def extract_test_funcs(tree: ast.AST) -> list[ast.FunctionDef]:\n",
        "    return [n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n",
        "\n",
        "def has_assert_or_raises(tree: ast.AST, code: str) -> bool:\n",
        "    has_assert_stmt = any(isinstance(n, ast.Assert) for n in ast.walk(tree))\n",
        "    has_pytest_raises = bool(RE_PYTEST_RAISES.search(code))\n",
        "    return has_assert_stmt or has_pytest_raises\n",
        "\n",
        "def uses_importlib(code: str) -> bool:\n",
        "    return bool(RE_IMPORTLIB.search(code))\n",
        "\n",
        "# ===== 가드형 skip 허용 (AST 기반) =====\n",
        "def _parent_map(tree: ast.AST):\n",
        "    parent = {}\n",
        "    for node in ast.walk(tree):\n",
        "        for child in ast.iter_child_nodes(node):\n",
        "            parent[child] = node\n",
        "    return parent\n",
        "\n",
        "def _is_guarded_skip(call: ast.Call, parent_map, src: str) -> bool:\n",
        "    \"\"\"\n",
        "    허용 가드:\n",
        "      (1) if <expr> is None: pytest.skip(...)\n",
        "      (2) except ImportError/NameError: pytest.skip(...)\n",
        "    \"\"\"\n",
        "    cur = call\n",
        "    while cur in parent_map:\n",
        "        cur = parent_map[cur]\n",
        "        if isinstance(cur, ast.If):\n",
        "            test = cur.test\n",
        "            if (\n",
        "                isinstance(test, ast.Compare)\n",
        "                and len(test.ops) == 1\n",
        "                and isinstance(test.ops[0], ast.Is)\n",
        "                and len(test.comparators) == 1\n",
        "                and isinstance(test.comparators[0], ast.Constant)\n",
        "                and test.comparators[0].value is None\n",
        "            ):\n",
        "                return True\n",
        "        if isinstance(cur, ast.ExceptHandler):\n",
        "            t = cur.type\n",
        "            if isinstance(t, ast.Name) and t.id in {\"ImportError\", \"NameError\"}:\n",
        "                return True\n",
        "            if isinstance(t, ast.Tuple) and any(isinstance(e, ast.Name) and e.id in {\"ImportError\", \"NameError\"} for e in t.elts):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def has_unconditional_skip(code: str) -> tuple[bool, list[int]]:\n",
        "    try:\n",
        "        tree = ast.parse(code)\n",
        "    except SyntaxError:\n",
        "        return (False, [])\n",
        "    parent = _parent_map(tree)\n",
        "    bad_lines = []\n",
        "    for node in ast.walk(tree):\n",
        "        if isinstance(node, ast.Call):\n",
        "            f = node.func\n",
        "            if isinstance(f, ast.Attribute) and isinstance(f.value, ast.Name) and f.value.id == \"pytest\" and f.attr == \"skip\":\n",
        "                if not _is_guarded_skip(node, parent, code):\n",
        "                    bad_lines.append(getattr(node, \"lineno\", -1))\n",
        "    return (len(bad_lines) > 0, bad_lines)\n",
        "\n",
        "# ---------- 최소 실행 요건 ----------\n",
        "def minimal_viability_checks(code: str) -> tuple[bool, list[str], dict]:\n",
        "    reasons = []\n",
        "    meta = {\"warnings\": []}\n",
        "    if len(code.strip()) < 60:\n",
        "        reasons.append(\"too_short\")\n",
        "\n",
        "    tree, synerr = parse_ast_or_error(code)\n",
        "    if synerr:\n",
        "        reasons.append(synerr)\n",
        "        return False, reasons, meta\n",
        "\n",
        "    tests = extract_test_funcs(tree)\n",
        "    if not tests:\n",
        "        reasons.append(\"no_test_functions\")\n",
        "    if not has_assert_or_raises(tree, code):\n",
        "        reasons.append(\"no_assert_or_raises\")\n",
        "    if not uses_importlib(code):\n",
        "        reasons.append(\"no_importlib_import_module\")\n",
        "\n",
        "    if tests and not any(\"hits_L\" in t.name for t in tests):\n",
        "        meta[\"warnings\"].append(\"missing_hits_L_in_test_name\")\n",
        "\n",
        "    # 무조건 skip 제외\n",
        "    has_bad_skip, bad_lines = has_unconditional_skip(code)\n",
        "    if has_bad_skip:\n",
        "        reasons.append(f\"unconditional_skip_detected@{bad_lines}\")\n",
        "\n",
        "    # runner 금지 패턴 감지\n",
        "    if re.search(r\"(?m)^\\s*pytest\\.main\\s*\\(\", code):\n",
        "        reasons.append(\"forbidden_runner_invocation:pytest.main\")\n",
        "    if re.search(r\"(?m)^\\s*unittest\\.main\\s*\\(\", code):\n",
        "        reasons.append(\"forbidden_runner_invocation:unittest.main\")\n",
        "    if re.search(r\"(?ms)^\\s*if\\s+__name__\\s*==\\s*['\\\"]__main__['\\\"]\\s*:\", code):\n",
        "        meta.setdefault(\"warnings\", []).append(\"sanitizable_main_guard_present\")\n",
        "\n",
        "    return (len(reasons) == 0), reasons, meta\n",
        "\n",
        "# ---------- OpenAI 호출 ----------\n",
        "@backoff.on_exception(backoff.expo, (APIConnectionError, APIError, RateLimitError), max_tries=8, max_time=300)\n",
        "def call_openai_with_retry(messages):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        timeout=180.0,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# ---------- 메인 루프 ----------\n",
        "gen_log_path = ART_DIR / \"gen_log.jsonl\"\n",
        "ok_count = 0\n",
        "fail_count = 0\n",
        "\n",
        "with LLM_PROMPTS_PATH.open(\"r\", encoding=\"utf-8\") as f_in, gen_log_path.open(\"w\", encoding=\"utf-8\") as f_log:\n",
        "    for line in f_in:\n",
        "        rec = json.loads(line)\n",
        "        goal_id = rec[\"meta\"][\"id\"]\n",
        "        messages = rec[\"messages\"]\n",
        "        print(f\"\\n🚀 Goal {goal_id} 테스트 생성 요청…\")\n",
        "\n",
        "        # 1) 모델 호출\n",
        "        try:\n",
        "            out_text = call_openai_with_retry(messages)\n",
        "        except Exception as e:\n",
        "            fail_count += 1\n",
        "            write_error(goal_id, \"request_error\", {\"error\": str(e)})\n",
        "            print(f\"❌ Goal {goal_id} 요청 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 2) 원문 보관\n",
        "        (RAW_DIR / f\"goal_{goal_id}_raw.json\").write_text(out_text, encoding=\"utf-8\")\n",
        "\n",
        "        # 3) JSON 파싱\n",
        "        try:\n",
        "            cleaned = strip_fences(out_text)\n",
        "            result = json.loads(cleaned)\n",
        "        except Exception as e:\n",
        "            fail_count += 1\n",
        "            write_error(goal_id, \"json_parse_error\", {\"error\": str(e), \"raw\": out_text[:2000]})\n",
        "            print(f\"❌ Goal {goal_id} JSON 파싱 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 4) 스키마 검증\n",
        "        ok_schema, schema_reasons = validate_json_schema(result)\n",
        "        if not ok_schema:\n",
        "            fail_count += 1\n",
        "            write_error(goal_id, \"schema_error\", {\"reasons\": schema_reasons, \"result\": result})\n",
        "            print(f\"❌ Goal {goal_id} 스키마 오류: {schema_reasons}\")\n",
        "            continue\n",
        "\n",
        "        tests = result.get(\"tests\", [])\n",
        "        base_name = result.get(\"filename\")\n",
        "        suffix = \".py\"\n",
        "        if base_name:\n",
        "            base_name = Path(base_name).name\n",
        "            suffix = Path(base_name).suffix or \".py\"\n",
        "\n",
        "        # 5) 테스트별 구조/요건 검증 후 저장\n",
        "        saved_files = []\n",
        "        excluded = []\n",
        "        for idx, t in enumerate(tests, start=1):\n",
        "            name = t.get(\"name\", f\"test_{goal_id}_{idx}\")\n",
        "            code = strip_fences(t.get(\"code\", \"\"))\n",
        "            code = sanitize_test_code(code)  # runner 제거\n",
        "\n",
        "            ok_min, reasons, meta = minimal_viability_checks(code)\n",
        "            if not ok_min:\n",
        "                excluded.append({\"index\": idx, \"name\": name, \"reasons\": reasons, **meta})\n",
        "                write_error(goal_id, \"min_viability\", {\"index\": idx, \"name\": name, \"reasons\": reasons, **meta}, idx=idx)\n",
        "                print(f\"⚠️ Goal {goal_id} 테스트 #{idx} 제외: {reasons}\")\n",
        "                continue\n",
        "\n",
        "            if len(tests) == 1 and result.get(\"filename\"):\n",
        "                out_stem = Path(base_name).stem\n",
        "            else:\n",
        "                slug = slugify(result.get(\"filename\", f\"goal_{goal_id}\"))\n",
        "                out_stem = f\"test_{goal_id}_{slug}_{idx}\" if len(tests) > 1 else f\"test_{goal_id}_{slug}\"\n",
        "\n",
        "            out_path = ensure_unique_path(GEN_DIR / f\"{out_stem}{suffix}\")\n",
        "            out_path.write_text(code, encoding=\"utf-8\")\n",
        "            saved_files.append(out_path.name)\n",
        "            print(f\"✅ 저장: {out_path.name}  (warnings: {','.join(meta.get('warnings', [])) or '없음'})\")\n",
        "\n",
        "        # 6) 결과 정리\n",
        "        if saved_files:\n",
        "            ok_count += 1\n",
        "            f_log.write(json.dumps({\n",
        "                \"goal_id\": goal_id,\n",
        "                \"saved_files\": saved_files,\n",
        "                \"excluded_tests\": excluded,\n",
        "            }, ensure_ascii=False) + \"\\n\")\n",
        "        else:\n",
        "            fail_count += 1\n",
        "            write_error(goal_id, \"no_valid_tests\", {\n",
        "                \"result_head\": result if len(json.dumps(result)) < 4000 else \"omitted(large)\",\n",
        "                \"excluded_tests\": excluded\n",
        "            })\n",
        "            print(f\"❌ Goal {goal_id} 유효 테스트 없음 → 기록만 남김\")\n",
        "\n",
        "print(f\"\\n✅ 생성 단계 종료: 성공 {ok_count} / 실패 {fail_count}\")\n",
        "print(f\"   • 저장 폴더 : {GEN_DIR}\")\n",
        "print(f\"   • 원문 보관 : {RAW_DIR}\")\n",
        "print(f\"   • 에러/제외 : {ERR_DIR}\")\n",
        "print(f\"   • 로그 파일 : {gen_log_path}\")\n"
      ],
      "metadata": {
        "id": "pYNqW94ih1mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7efef8-fadc-4347-b867-17ccabb9e955"
      },
      "id": "pYNqW94ih1mr",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Goal 0001 테스트 생성 요청…\n",
            "✅ 저장: test_0001_test_gen_0001_banking_service_deposit_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0001_test_gen_0001_banking_service_deposit_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0002 테스트 생성 요청…\n",
            "✅ 저장: test_0002_test_gen_0002_run_worker_module_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0002_test_gen_0002_run_worker_module_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0003 테스트 생성 요청…\n",
            "✅ 저장: test_0003_test_gen_0003_run_workflow_module_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0003_test_gen_0003_run_workflow_module_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0004 테스트 생성 요청…\n",
            "✅ 저장: test_0004_test_gen_0004_activities_refund_py_1.py  (warnings: missing_hits_L_in_test_name)\n",
            "✅ 저장: test_0004_test_gen_0004_activities_refund_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0005 테스트 생성 요청…\n",
            "✅ 저장: test_0005_test_gen_0005_run_workflow_main_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0005_test_gen_0005_run_workflow_main_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0006 테스트 생성 요청…\n",
            "✅ 저장: test_gen_0006_banking_service_deposit_that_fails.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0007 테스트 생성 요청…\n",
            "✅ 저장: test_0007_test_gen_0007_activities_deposit_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0007_test_gen_0007_activities_deposit_py_2.py  (warnings: missing_hits_L_in_test_name)\n",
            "\n",
            "🚀 Goal 0008 테스트 생성 요청…\n",
            "✅ 저장: test_0008_test_gen_0008_activities_deposit_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0008_test_gen_0008_activities_deposit_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0009 테스트 생성 요청…\n",
            "✅ 저장: test_0009_test_gen_0009_activities_refund_py_1.py  (warnings: 없음)\n",
            "✅ 저장: test_0009_test_gen_0009_activities_refund_py_2.py  (warnings: 없음)\n",
            "\n",
            "🚀 Goal 0010 테스트 생성 요청…\n",
            "✅ 저장: test_gen_0010_run_workflow_main.py  (warnings: 없음)\n",
            "\n",
            "✅ 생성 단계 종료: 성공 10 / 실패 0\n",
            "   • 저장 폴더 : /content/money-transfer-project-template-python/generated_tests\n",
            "   • 원문 보관 : /content/money-transfer-project-template-python/run_artifacts/run1/_raw\n",
            "   • 에러/제외 : /content/money-transfer-project-template-python/run_artifacts/run1/_errors\n",
            "   • 로그 파일 : /content/money-transfer-project-template-python/run_artifacts/run1/gen_log.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-5) 기존 tests + 생성 tests 격리 실행 · 로그 수집 · 샤드 결합 · 향상치 계산\n",
        "import os, sys, json, re, time, subprocess, shutil, shlex\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "from lxml import etree\n",
        "\n",
        "# ==== 경로/상수 ====\n",
        "assert 'PROJ' in globals(), \"3-0 단계를 먼저 실행하세요.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ / \"run_artifacts\" / \"run1\"\n",
        "GEN_DIR = PROJ / \"generated_tests\"\n",
        "TESTS_DIR = PROJ / \"tests\"  # 기존 테스트 루트\n",
        "LOG_DIR = ART_DIR / \"logs\"\n",
        "COV_SHARDS_DIR = ART_DIR / \"cov_shards\"\n",
        "HTML_DIR_GEN = PROJ / \"htmlcov_gen\"\n",
        "\n",
        "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
        "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "COV_SHARDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "HTML_DIR_GEN.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RCFILE = PROJ / \".coveragerc\"\n",
        "rc_opt = f\" --rcfile {RCFILE}\" if RCFILE.exists() else \"\"\n",
        "\n",
        "# 실행 파라미터\n",
        "PY_EXE = sys.executable\n",
        "TIMEOUT_SEC_GEN = 30            # 생성 테스트 파일 1개당 타임아웃\n",
        "TIMEOUT_SEC_BASE = 120          # 기존 tests 전체 실행 타임아웃\n",
        "PYTEST_FLAGS = \"-q -s\"\n",
        "ENV_BASE = os.environ.copy()\n",
        "\n",
        "# goal_id 추출\n",
        "RE_GOAL = re.compile(r\"(?:^|[_-])(?P<gid>\\d{4})(?:[_-]|$)\")\n",
        "\n",
        "# ==== 유틸 ====\n",
        "def goal_id_from_name(name: str) -> str | None:\n",
        "    m = RE_GOAL.search(name)\n",
        "    return m.group(\"gid\") if m else None\n",
        "\n",
        "def sh(cmd: str, cwd: Path | None = None, timeout: int | None = None, env: dict | None = None):\n",
        "    try:\n",
        "        p = subprocess.run(\n",
        "            cmd, cwd=str(cwd or PROJ), env=env or ENV_BASE,\n",
        "            shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
        "            timeout=timeout, text=True\n",
        "        )\n",
        "        return p.returncode, p.stdout, p.stderr, False\n",
        "    except subprocess.TimeoutExpired as e:\n",
        "        return 124, e.stdout or \"\", e.stderr or \"\", True\n",
        "\n",
        "def list_generated_test_files() -> list[Path]:\n",
        "    if not GEN_DIR.exists():\n",
        "        return []\n",
        "    return sorted([p for p in GEN_DIR.glob(\"*.py\") if p.is_file()])\n",
        "\n",
        "def rel_to_proj(p: Path) -> str:\n",
        "    try:\n",
        "        return str(p.resolve().relative_to(PROJ))\n",
        "    except Exception:\n",
        "        return str(p.resolve())\n",
        "\n",
        "# ==== 0) 산출물 파일 경로 ====\n",
        "results_jsonl = ART_DIR / \"results.jsonl\"\n",
        "manifest_path = ART_DIR / \"manifest.json\"\n",
        "coverage_json_path = ART_DIR / \"coverage_gen.json\"     # 이번 라운드 통합\n",
        "coverage_xml_path  = ART_DIR / \"coverage_gen.xml\"\n",
        "coverage_base_json = ART_DIR / \"coverage_base.json\"    # 3-1에서 산출한 기준선\n",
        "\n",
        "for old in [results_jsonl, coverage_json_path, coverage_xml_path]:\n",
        "    if old.exists():\n",
        "        old.unlink()\n",
        "\n",
        "runs = []\n",
        "ok = fail = to_cnt = 0\n",
        "\n",
        "# ==== 1) 기존 tests/ 전체 1회 실행 → 베이스라인 샤드 ====\n",
        "if TESTS_DIR.exists() and any(TESTS_DIR.glob(\"test*.py\")):\n",
        "    shard_base = COV_SHARDS_DIR / \".coverage.__baseline_tests__\"\n",
        "    env = ENV_BASE.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{PROJ}:{env.get('PYTHONPATH','')}\"\n",
        "    env[\"COVERAGE_FILE\"] = str(shard_base)\n",
        "    env.setdefault(\"NO_PROXY\", \"*\")\n",
        "\n",
        "    target = rel_to_proj(TESTS_DIR)  # \"tests\"\n",
        "    cmd = f\"{PY_EXE} -m coverage run{rc_opt} -m pytest {PYTEST_FLAGS} {shlex.quote(target)}\"\n",
        "\n",
        "    start = time.time()\n",
        "    ts_start = datetime.now(timezone.utc).isoformat()\n",
        "    rc, out, err, timed_out = sh(cmd, cwd=PROJ, timeout=TIMEOUT_SEC_BASE, env=env)\n",
        "    dur = round(time.time() - start, 3)\n",
        "    ts_end = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    # 로그 보관\n",
        "    (LOG_DIR / \"__baseline_tests__.out.txt\").write_text(out, encoding=\"utf-8\")\n",
        "    (LOG_DIR / \"__baseline_tests__.err.txt\").write_text(err, encoding=\"utf-8\")\n",
        "\n",
        "    runs.append({\n",
        "        \"test_file\": \"__BASELINE_SUITE__\",\n",
        "        \"goal_id\": None,\n",
        "        \"start_utc\": ts_start,\n",
        "        \"end_utc\": ts_end,\n",
        "        \"duration_sec\": dur,\n",
        "        \"returncode\": rc,\n",
        "        \"timed_out\": timed_out,\n",
        "        \"stdout_len\": len(out),\n",
        "        \"stderr_len\": len(err),\n",
        "        \"shard_path\": str(shard_base),\n",
        "        \"invoked_path\": target,\n",
        "    })\n",
        "    if timed_out:\n",
        "        to_cnt += 1\n",
        "        print(f\"⏱️ TIMEOUT __BASELINE_SUITE__ ({dur}s)\")\n",
        "    elif rc == 0:\n",
        "        ok += 1\n",
        "        print(f\"✅ PASS   __BASELINE_SUITE__ ({dur}s)\")\n",
        "    else:\n",
        "        fail += 1\n",
        "        first_err = (err.strip().splitlines() or [\"\"])[0]\n",
        "        print(f\"❌ FAIL   __BASELINE_SUITE__ (rc={rc}, {dur}s) :: {first_err}\")\n",
        "else:\n",
        "    print(\"ℹ️ tests/ 디렉터리 또는 테스트 파일이 없어 베이스라인 개별 실행을 건너뜀.\")\n",
        "\n",
        "# ==== 2) 생성 테스트 파일 개별 격리 실행 ====\n",
        "test_files = list_generated_test_files()\n",
        "print(f\"🧪 생성 테스트 파일: {len(test_files)}개\")\n",
        "for tf in test_files:\n",
        "    name = tf.name\n",
        "    gid = goal_id_from_name(name) or \"----\"\n",
        "    shard = COV_SHARDS_DIR / f\".coverage.{name}\"\n",
        "\n",
        "    env = ENV_BASE.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{PROJ}:{env.get('PYTHONPATH','')}\"\n",
        "    env[\"COVERAGE_FILE\"] = str(shard)\n",
        "    env.setdefault(\"NO_PROXY\", \"*\")\n",
        "\n",
        "    target = rel_to_proj(tf)   # e.g. \"generated_tests/test_0001_...py\"\n",
        "    cmd = f\"{PY_EXE} -m coverage run{rc_opt} -m pytest {PYTEST_FLAGS} {shlex.quote(target)}\"\n",
        "\n",
        "    start = time.time()\n",
        "    ts_start = datetime.now(timezone.utc).isoformat()\n",
        "    rc, out, err, timed_out = sh(cmd, cwd=PROJ, timeout=TIMEOUT_SEC_GEN, env=env)\n",
        "    dur = round(time.time() - start, 3)\n",
        "    ts_end = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    # 로그 저장\n",
        "    (LOG_DIR / f\"{name}.out.txt\").write_text(out, encoding=\"utf-8\")\n",
        "    (LOG_DIR / f\"{name}.err.txt\").write_text(err, encoding=\"utf-8\")\n",
        "\n",
        "    runs.append({\n",
        "        \"test_file\": name,\n",
        "        \"goal_id\": gid,\n",
        "        \"start_utc\": ts_start,\n",
        "        \"end_utc\": ts_end,\n",
        "        \"duration_sec\": dur,\n",
        "        \"returncode\": rc,\n",
        "        \"timed_out\": timed_out,\n",
        "        \"stdout_len\": len(out),\n",
        "        \"stderr_len\": len(err),\n",
        "        \"shard_path\": str(shard),\n",
        "        \"invoked_path\": target,\n",
        "    })\n",
        "\n",
        "    if timed_out:\n",
        "        to_cnt += 1\n",
        "        print(f\"⏱️ TIMEOUT {name} ({dur}s)\")\n",
        "    elif rc == 0:\n",
        "        ok += 1\n",
        "        print(f\"✅ PASS   {name} ({dur}s)\")\n",
        "    else:\n",
        "        fail += 1\n",
        "        first_err = (err.strip().splitlines() or [\"\"])[0]\n",
        "        print(f\"❌ FAIL   {name} (rc={rc}, {dur}s) :: {first_err}\")\n",
        "\n",
        "# 실행 기록 저장\n",
        "with results_jsonl.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for r in runs:\n",
        "        f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "manifest = {\n",
        "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"project\": str(PROJ),\n",
        "    \"run_dir\": str(ART_DIR),\n",
        "    \"tests_total\": (len(test_files) + (1 if any(x['test_file']==\"__BASELINE_SUITE__\" for x in runs) else 0)),\n",
        "    \"pass\": ok,\n",
        "    \"fail\": fail,\n",
        "    \"timeout\": to_cnt,\n",
        "    \"logs_dir\": str(LOG_DIR),\n",
        "    \"cov_shards_dir\": str(COV_SHARDS_DIR),\n",
        "}\n",
        "manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"\\n📦 실행 요약:\", json.dumps({\"pass\": ok, \"fail\": fail, \"timeout\": to_cnt, \"total\": manifest['tests_total']}, ensure_ascii=False))\n",
        "\n",
        "# ==== 3) 커버리지 결합(JSON/XML/HTML) ====\n",
        "shards = sorted([p for p in COV_SHARDS_DIR.iterdir() if p.name.startswith(\".coverage.\")])\n",
        "if not shards:\n",
        "    print(\"⚠️ 커버리지 샤드가 없습니다. 테스트가 즉시 실패했을 수 있습니다.\")\n",
        "else:\n",
        "    subprocess.call(f\"coverage erase{rc_opt}\", shell=True, cwd=str(PROJ))\n",
        "    combine_cmd = \"coverage combine\" + rc_opt + \" \" + \" \".join(shlex.quote(str(p)) for p in shards)\n",
        "    print(\"> \", combine_cmd)\n",
        "    subprocess.call(combine_cmd, shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage json -o {coverage_json_path.name}{rc_opt}\", shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage xml  -o {coverage_xml_path.name}{rc_opt}\",  shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage html -d {HTML_DIR_GEN.name}{rc_opt}\",       shell=True, cwd=str(PROJ))\n",
        "\n",
        "    # 결과 파일을 run_artifacts에 복사 보관\n",
        "    src_json = PROJ / coverage_json_path.name\n",
        "    src_xml  = PROJ / coverage_xml_path.name\n",
        "    if src_json.exists(): shutil.copy2(src_json, coverage_json_path)\n",
        "    if src_xml.exists():  shutil.copy2(src_xml,  coverage_xml_path)\n",
        "\n",
        "    print(\"✅ 커버리지 결합 완료\")\n",
        "    print(\" - JSON :\", coverage_json_path)\n",
        "    print(\" - XML  :\", coverage_xml_path)\n",
        "    print(\" - HTML :\", HTML_DIR_GEN / \"index.html\")\n",
        "\n",
        "# ==== 4) 분기 관측/목표 달성률 계산 ====\n",
        "observed_outcomes_gen = {}\n",
        "branch_points = full_hit = half_hit = zero_hit = 0\n",
        "\n",
        "if coverage_xml_path.exists():\n",
        "    try:\n",
        "        xml_root = etree.parse(str(coverage_xml_path)).getroot()\n",
        "        for cls in xml_root.findall(\".//class\"):\n",
        "            filename = cls.get(\"filename\") or \"\"\n",
        "            if not filename:\n",
        "                continue\n",
        "            abs_path = (PROJ / filename).resolve() if not Path(filename).is_absolute() else Path(filename)\n",
        "            for line in cls.findall(\"./lines/line\"):\n",
        "                if line.get(\"branch\") != \"true\":\n",
        "                    continue\n",
        "                try:\n",
        "                    num = int(line.get(\"number\"))\n",
        "                except Exception:\n",
        "                    continue\n",
        "                cond = line.get(\"condition-coverage\")  # \"50% (1/2)\"\n",
        "                covered = total = 0\n",
        "                if cond:\n",
        "                    m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", cond)\n",
        "                    if m:\n",
        "                        covered, total = int(m.group(1)), int(m.group(2))\n",
        "                if total == 0:\n",
        "                    continue\n",
        "                observed_outcomes_gen.setdefault(str(abs_path), {})[num] = {\n",
        "                    \"covered\": covered, \"total\": total, \"ratio\": round(covered/total, 3)\n",
        "                }\n",
        "                branch_points += 1\n",
        "                if covered == 0: zero_hit += 1\n",
        "                elif covered == total: full_hit += 1\n",
        "                else: half_hit += 1\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ coverage_xml 파싱 실패:\", e)\n",
        "\n",
        "(ART_DIR / \"observed_outcomes_gen.json\").write_text(\n",
        "    json.dumps(observed_outcomes_gen, ensure_ascii=False, indent=2),\n",
        "    encoding=\"utf-8\"\n",
        ")\n",
        "\n",
        "print(f\"🧮 분기 관측 요약 → total:{branch_points}, full:{full_hit}, half:{half_hit}, zero:{zero_hit}\")\n",
        "\n",
        "# ==== 5) 목표 달성률(기본) ====\n",
        "GOALS_FILE = ART_DIR / \"goals_ranked.json\"\n",
        "if GOALS_FILE.exists() and coverage_json_path.exists():\n",
        "    cov_json = json.loads((coverage_json_path).read_text(encoding=\"utf-8\"))\n",
        "    files_map = cov_json.get(\"files\", {})\n",
        "\n",
        "    def line_hit(fpath: str, ln: int) -> bool:\n",
        "        finfo = files_map.get(fpath) or files_map.get(str(Path(fpath).resolve()))\n",
        "        if not finfo:\n",
        "            return False\n",
        "        executed = set(finfo.get(\"executed_lines\", []) or [])\n",
        "        return ln in executed\n",
        "\n",
        "    goals = json.loads(GOALS_FILE.read_text(encoding=\"utf-8\"))\n",
        "    goal_stats = []\n",
        "    for g in goals:\n",
        "        f = g[\"file\"]\n",
        "        abs1 = str((PROJ / f).resolve())\n",
        "        abs2 = f\n",
        "        hit = sum(1 for ln in g.get(\"target_lines\", []) if line_hit(abs1, ln) or line_hit(abs2, ln))\n",
        "        total = len(g.get(\"target_lines\", [])) or 1\n",
        "        goal_stats.append({\"id\": g[\"id\"], \"hit\": hit, \"total\": total, \"rate\": round(hit/total, 3)})\n",
        "\n",
        "    (ART_DIR / \"goal_achievements.json\").write_text(\n",
        "        json.dumps(goal_stats, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    hit_goals = sum(1 for s in goal_stats if s[\"hit\"] > 0)\n",
        "    print(f\"🎯 목표 달성률: {hit_goals}/{len(goal_stats)} 목표가 ≥1 라인 도달\")\n",
        "\n",
        "# ==== 6) 베이스라인 대비 향상치(delta) 계산 ====\n",
        "def load_json(p: Path, default=None):\n",
        "    try:\n",
        "        return json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "base = load_json(coverage_base_json, {\"files\": {}}) or {\"files\": {}}\n",
        "gen  = load_json(coverage_json_path, {\"files\": {}}) or {\"files\": {}}\n",
        "base_files = base.get(\"files\", {})\n",
        "gen_files  = gen.get(\"files\", {})\n",
        "\n",
        "def _sum_len(key, d):\n",
        "    return sum(len((d.get(f, {}) or {}).get(key, []) or []) for f in d.keys())\n",
        "\n",
        "base_exec = _sum_len(\"executed_lines\", base_files)\n",
        "base_miss = _sum_len(\"missing_lines\",  base_files)\n",
        "gen_exec  = _sum_len(\"executed_lines\", gen_files)\n",
        "gen_miss  = _sum_len(\"missing_lines\",  gen_files)\n",
        "\n",
        "delta = {\n",
        "    \"executed_lines_delta\": gen_exec - base_exec,\n",
        "    \"missing_lines_delta\":  base_miss - gen_miss,   # +면 미싱 감소\n",
        "    \"base_executed\": base_exec,\n",
        "    \"gen_executed\":  gen_exec,\n",
        "    \"base_missing\":  base_miss,\n",
        "    \"gen_missing\":   gen_miss,\n",
        "}\n",
        "(ART_DIR / \"coverage_delta.json\").write_text(json.dumps(delta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"📈 베이스라인 대비 향상치:\", json.dumps(delta, ensure_ascii=False))\n",
        "\n",
        "print(\"✅ 3-5 완료: (기존+생성) 격리 실행/샤드 결합/분기·목표·향상치 산출\")\n"
      ],
      "metadata": {
        "id": "cxb2ea7Wi2Zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59115233-a64e-45ad-b218-b67e9e4131ed"
      },
      "id": "cxb2ea7Wi2Zk",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PASS   __BASELINE_SUITE__ (14.487s)\n",
            "🧪 생성 테스트 파일: 18개\n",
            "❌ FAIL   test_0001_test_gen_0001_banking_service_deposit_py_1.py (rc=2, 12.028s) :: \n",
            "❌ FAIL   test_0001_test_gen_0001_banking_service_deposit_py_2.py (rc=2, 11.899s) :: \n",
            "❌ FAIL   test_0002_test_gen_0002_run_worker_module_py_1.py (rc=1, 14.684s) :: \n",
            "❌ FAIL   test_0002_test_gen_0002_run_worker_module_py_2.py (rc=1, 13.682s) :: \n",
            "✅ PASS   test_0003_test_gen_0003_run_workflow_module_py_1.py (13.209s)\n",
            "✅ PASS   test_0003_test_gen_0003_run_workflow_module_py_2.py (13.079s)\n",
            "❌ FAIL   test_0004_test_gen_0004_activities_refund_py_1.py (rc=1, 12.762s) :: \n",
            "❌ FAIL   test_0004_test_gen_0004_activities_refund_py_2.py (rc=1, 12.69s) :: \n",
            "❌ FAIL   test_0005_test_gen_0005_run_workflow_main_py_1.py (rc=1, 13.194s) :: \n",
            "❌ FAIL   test_0005_test_gen_0005_run_workflow_main_py_2.py (rc=1, 13.302s) :: \n",
            "✅ PASS   test_0007_test_gen_0007_activities_deposit_py_1.py (12.812s)\n",
            "✅ PASS   test_0007_test_gen_0007_activities_deposit_py_2.py (12.81s)\n",
            "❌ FAIL   test_0008_test_gen_0008_activities_deposit_py_1.py (rc=2, 13.028s) :: \n",
            "❌ FAIL   test_0008_test_gen_0008_activities_deposit_py_2.py (rc=2, 13.118s) :: \n",
            "❌ FAIL   test_0009_test_gen_0009_activities_refund_py_1.py (rc=2, 13.083s) :: \n",
            "❌ FAIL   test_0009_test_gen_0009_activities_refund_py_2.py (rc=2, 19.766s) :: \n",
            "❌ FAIL   test_gen_0006_banking_service_deposit_that_fails.py (rc=2, 27.008s) :: \n",
            "❌ FAIL   test_gen_0010_run_workflow_main.py (rc=1, 13.343s) :: \n",
            "\n",
            "📦 실행 요약: {\"pass\": 5, \"fail\": 14, \"timeout\": 0, \"total\": 19}\n",
            ">  coverage combine --rcfile /content/money-transfer-project-template-python/.coveragerc /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.__baseline_tests__ /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0001_test_gen_0001_banking_service_deposit_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0001_test_gen_0001_banking_service_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0002_test_gen_0002_run_worker_module_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0002_test_gen_0002_run_worker_module_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0003_test_gen_0003_run_workflow_module_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0003_test_gen_0003_run_workflow_module_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0004_test_gen_0004_activities_refund_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0004_test_gen_0004_activities_refund_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0005_test_gen_0005_run_workflow_main_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0005_test_gen_0005_run_workflow_main_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0007_test_gen_0007_activities_deposit_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0007_test_gen_0007_activities_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0008_test_gen_0008_activities_deposit_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0008_test_gen_0008_activities_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0009_test_gen_0009_activities_refund_py_1.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0009_test_gen_0009_activities_refund_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_gen_0006_banking_service_deposit_that_fails.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_gen_0010_run_workflow_main.py\n",
            "✅ 커버리지 결합 완료\n",
            " - JSON : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_gen.json\n",
            " - XML  : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_gen.xml\n",
            " - HTML : /content/money-transfer-project-template-python/htmlcov_gen/index.html\n",
            "🧮 분기 관측 요약 → total:5, full:3, half:2, zero:0\n",
            "🎯 목표 달성률: 2/10 목표가 ≥1 라인 도달\n",
            "📈 베이스라인 대비 향상치: {\"executed_lines_delta\": 15, \"missing_lines_delta\": 15, \"base_executed\": 102, \"gen_executed\": 117, \"base_missing\": 54, \"gen_missing\": 39}\n",
            "✅ 3-5 완료: (기존+생성) 격리 실행/샤드 결합/분기·목표·향상치 산출\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #@title 3-6) 테스트 보완 – Refinement-based Adaptive Round (coverage_gen 기반 미도달·분포 주입)\n",
        "import os, sys, json, re\n",
        "from pathlib import Path\n",
        "\n",
        "# ==== 경로/상수 ====\n",
        "assert 'PROJ' in globals(), \"3-0 단계를 먼저 실행하세요.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ / \"run_artifacts\" / \"run1\"\n",
        "GEN_DIR = PROJ / \"generated_tests\"\n",
        "LOG_DIR = ART_DIR / \"logs\"\n",
        "HTML_GEN_DIR = PROJ / \"htmlcov_gen\"\n",
        "\n",
        "COV_BASE_JSON = ART_DIR / \"coverage_base.json\"       # 3-1 기준선 (참고용)\n",
        "COV_GEN_JSON  = ART_DIR / \"coverage_gen.json\"        # 3-5/3-8 통합 커버리지(필수)\n",
        "GOALS_FILE    = ART_DIR / \"goals_ranked.json\"        # 3-2 목표\n",
        "UNCV_MAP_JSON = ART_DIR / \"uncovered_map_base.json\"  # 3-1 미커버 라인(참고용)\n",
        "RESULTS_JL    = ART_DIR / \"results.jsonl\"            # 3-5/3-8 실행 결과 로그 인덱스(참고용)\n",
        "\n",
        "# 선별/배치 파라미터\n",
        "NEAR_MISS_WINDOW = 2\n",
        "BATCH_SIZE = 3\n",
        "MAX_ROUNDS = 5\n",
        "TOPK_FILES = 10   # 전역 미커버 상위 파일 요약 개수\n",
        "\n",
        "# ==== 라운드 디렉터리 자동 증가 ====\n",
        "def next_round_dir(base: Path) -> Path:\n",
        "    i = 1\n",
        "    while True:\n",
        "        cand = base / f\"refine_round{i}\"\n",
        "        if not cand.exists():\n",
        "            cand.mkdir(parents=True, exist_ok=True)\n",
        "            return cand\n",
        "        i += 1\n",
        "\n",
        "REFINE_DIR = next_round_dir(ART_DIR)\n",
        "REFINE_PROMPTS = REFINE_DIR / \"llm_refine_prompts.jsonl\"\n",
        "REFINE_SUMMARY = REFINE_DIR / \"refine_selection.json\"\n",
        "REFINE_TEST_EXPORT = REFINE_DIR / \"selected_tests_dump.json\"\n",
        "\n",
        "# ==== 유틸 ====\n",
        "def load_json(p: Path, default=None):\n",
        "    try:\n",
        "        return json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def read_text_safe(p: Path) -> str:\n",
        "    try:\n",
        "        return p.read_text(encoding=\"utf-8\")\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def first_lines(s: str, n=2000):\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    head = s[:n]\n",
        "    if len(s) > n:\n",
        "        head += \"\\n...<truncated>...\"\n",
        "    return head\n",
        "\n",
        "RE_GID = re.compile(r\"(?:^|[_-])(?P<gid>\\d{4})(?:[_-]|$)\")\n",
        "def goal_id_from_name(name: str) -> str | None:\n",
        "    m = RE_GID.search(name)\n",
        "    return m.group(\"gid\") if m else None\n",
        "\n",
        "def list_generated_tests_for_gid(gid: str) -> list[Path]:\n",
        "    \"\"\"goal id에 해당하는 생성/보강 테스트 후보들을 최신순으로 반환.\"\"\"\n",
        "    if not GEN_DIR.exists():\n",
        "        return []\n",
        "    cands = [p for p in GEN_DIR.glob(\"*.py\") if gid in p.name]\n",
        "    # 보강본(*_rN.py)을 우선, 숫자 큰 것 우선 → 없으면 기본 파일\n",
        "    def rank(p: Path):\n",
        "        m = re.search(r\"_r(\\d+)\\.py$\", p.name)\n",
        "        r = int(m.group(1)) if m else -1\n",
        "        return (0 if r >= 0 else 1, -r, -p.stat().st_mtime)\n",
        "    return sorted(cands, key=rank)\n",
        "\n",
        "def pick_latest_test_for_gid(gid: str) -> Path | None:\n",
        "    lst = list_generated_tests_for_gid(gid)\n",
        "    return lst[0] if lst else None\n",
        "\n",
        "# ==== 데이터 로드 ====\n",
        "cov_base = load_json(COV_BASE_JSON, {\"files\": {}}) or {\"files\": {}}\n",
        "cov_gen  = load_json(COV_GEN_JSON,  {\"files\": {}}) or {\"files\": {}}\n",
        "goals    = load_json(GOALS_FILE,    []) or []\n",
        "uncovered_map = load_json(UNCV_MAP_JSON, {}) or {}\n",
        "\n",
        "if not cov_gen or not goals:\n",
        "    raise SystemExit(\"필수 산출물(coverage_gen.json 또는 goals_ranked.json)이 없습니다. 3-2, 3-5/3-8 후 실행하세요.\")\n",
        "\n",
        "gen_files = cov_gen.get(\"files\", {}) or {}\n",
        "\n",
        "def _info_for(file_rel: str):\n",
        "    \"\"\"coverage_gen.json에서 상대/절대 키 모두 탐색.\"\"\"\n",
        "    return gen_files.get(file_rel) or gen_files.get(str((PROJ / file_rel).resolve()))\n",
        "\n",
        "def line_hit_in_gen(file_rel: str, ln: int) -> bool:\n",
        "    info = _info_for(file_rel)\n",
        "    if not info:\n",
        "        return False\n",
        "    return ln in set(info.get(\"executed_lines\", []) or [])\n",
        "\n",
        "def executed_set_in_gen(file_rel: str) -> set[int]:\n",
        "    info = _info_for(file_rel)\n",
        "    return set(info.get(\"executed_lines\", []) or []) if info else set()\n",
        "\n",
        "def missing_set_in_gen(file_rel: str) -> set[int]:\n",
        "    info = _info_for(file_rel)\n",
        "    return set(info.get(\"missing_lines\", []) or []) if info else set()\n",
        "\n",
        "# ==== A) coverage_gen.json에서 전역 미커버 라인 분포 추출 ====\n",
        "# 파일별 미커버 라인 집합 및 총합 집계\n",
        "global_uncovered_map = {}\n",
        "total_missing = 0\n",
        "for fkey, finfo in gen_files.items():\n",
        "    miss = sorted(set((finfo or {}).get(\"missing_lines\", []) or []))\n",
        "    if miss:\n",
        "        global_uncovered_map[fkey] = miss\n",
        "        total_missing += len(miss)\n",
        "\n",
        "# 전역 요약(상위 미커버 파일 TOPK)\n",
        "global_uncovered_summary = []\n",
        "for fkey, miss in sorted(global_uncovered_map.items(), key=lambda kv: len(kv[1]), reverse=True)[:TOPK_FILES]:\n",
        "    global_uncovered_summary.append({\n",
        "        \"file\": fkey,\n",
        "        \"missing_count\": len(miss),\n",
        "        \"missing_lines\": miss[:200],  # 너무 길면 잘라서 힌트만\n",
        "    })\n",
        "\n",
        "# ==== 1) 미도달 목표 판정 (coverage_gen 기준) ====\n",
        "miss_goals = []  # 보강 대상 후보\n",
        "for g in goals:\n",
        "    file_rel = g[\"file\"]\n",
        "    tlines = g.get(\"target_lines\", []) or []\n",
        "    hits = sum(1 for ln in tlines if line_hit_in_gen(file_rel, ln))\n",
        "    if hits == 0 and tlines:  # 목표 라인 ≥1줄도 못 맞춘 경우만 보강\n",
        "        # near-miss 판단(통합 실행 기준)\n",
        "        exed = executed_set_in_gen(file_rel)\n",
        "        neigh = set()\n",
        "        for t in tlines:\n",
        "            for k in range(-NEAR_MISS_WINDOW, NEAR_MISS_WINDOW + 1):\n",
        "                neigh.add(t + k)\n",
        "        near = len(exed & neigh) > 0\n",
        "        miss_goals.append({\n",
        "            \"goal_id\": g[\"id\"],\n",
        "            \"file\": file_rel,\n",
        "            \"function\": g.get(\"function\", {}),\n",
        "            \"target_lines\": tlines,\n",
        "            \"near_miss\": near\n",
        "        })\n",
        "\n",
        "# ==== 2) 각 미도달 goal → 최신 테스트 파일 매핑 & 프롬프트 입력 구성 ====\n",
        "selected = []\n",
        "for item in miss_goals:\n",
        "    gid = item[\"goal_id\"]\n",
        "    tfile = pick_latest_test_for_gid(gid)\n",
        "    if not tfile:\n",
        "        # 생성된 테스트가 없으면 스킵(다음 라운드에 새로 생성)\n",
        "        continue\n",
        "\n",
        "    original_code = read_text_safe(tfile)\n",
        "    out_log = read_text_safe(LOG_DIR / f\"{tfile.name}.out.txt\")\n",
        "    err_log = read_text_safe(LOG_DIR / f\"{tfile.name}.err.txt\")\n",
        "\n",
        "    # 해당 목표에서 아직 미도달한 타겟 라인(coverage_gen 기준)\n",
        "    still_missing = [ln for ln in item[\"target_lines\"] if not line_hit_in_gen(item[\"file\"], ln)]\n",
        "\n",
        "    # 현재 라운드 기준 그 파일의 전체 미커버 라인(coverage_gen 기준)\n",
        "    file_uncovered_remaining_gen = sorted(missing_set_in_gen(item[\"file\"]))\n",
        "\n",
        "    # baseline의 파일별 미커버 라인(참고용)\n",
        "    file_abs = str((PROJ / item[\"file\"]).resolve())\n",
        "    base_uncovered = uncovered_map.get(file_abs, uncovered_map.get(item[\"file\"], [])) or []\n",
        "\n",
        "    selected.append({\n",
        "        \"id\": f\"{gid}::{tfile.name}\",\n",
        "        \"goal_id\": gid,\n",
        "        \"target_file\": item[\"file\"],\n",
        "        \"target_lines\": item[\"target_lines\"],\n",
        "        \"near_miss\": item[\"near_miss\"],\n",
        "        \"uncovered_diff\": {\n",
        "            \"still_missing_target_lines\": sorted(still_missing),\n",
        "            \"file_uncovered_lines_baseline\": sorted(set(int(x) for x in base_uncovered)),\n",
        "            \"file_uncovered_remaining_gen\": file_uncovered_remaining_gen,   # ★ 현재 미커버(해당 파일)\n",
        "        },\n",
        "        \"run\": {\n",
        "            \"stdout_head\": first_lines(out_log, 1500),\n",
        "            \"stderr_head\": first_lines(err_log, 1500),\n",
        "        },\n",
        "        \"original_test_code\": original_code,\n",
        "    })\n",
        "\n",
        "# 선별 없으면 종료\n",
        "if not selected:\n",
        "    REFINE_PROMPTS.write_text(\"\", encoding=\"utf-8\")\n",
        "    REFINE_SUMMARY.write_text(json.dumps({\n",
        "        \"round_dir\": REFINE_DIR.name,\n",
        "        \"using_coverage_gen_only\": True,\n",
        "        \"selected\": 0,\n",
        "        \"reason\": \"모든 목표가 최소 1줄 이상 도달했거나, 해당 goal id의 테스트 파일이 없음\",\n",
        "        \"global_uncovered\": {\n",
        "            \"total_missing_lines\": total_missing,\n",
        "            \"top_files\": global_uncovered_summary\n",
        "        }\n",
        "    }, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(\"ℹ️ 미도달 목표가 없거나, 매칭 테스트가 없습니다. 보강 프롬프트를 만들지 않았습니다.\")\n",
        "    raise SystemExit(0)\n",
        "\n",
        "# ==== 3) 파일별 충돌 피하기(동일 파일 목표는 한 배치에 하나만) → 배치 구성 ====\n",
        "batches, bucket, seen_files = [], [], set()\n",
        "for rec in selected:\n",
        "    f = rec[\"target_file\"]\n",
        "    if f in seen_files or len(bucket) >= BATCH_SIZE:\n",
        "        if bucket:\n",
        "            batches.append(bucket)\n",
        "        bucket, seen_files = [], set()\n",
        "    bucket.append(rec)\n",
        "    seen_files.add(f)\n",
        "if bucket:\n",
        "    batches.append(bucket)\n",
        "\n",
        "# ==== 4) LLM 보강 프롬프트(JSONL) 생성 ====\n",
        "SYSTEM_REFINE = (\n",
        "    \"당신은 기존 pytest 테스트를 보강하여 미커버 영역(Target Lines)에 도달하도록 수정하는 전문가입니다.\\n\"\n",
        "    \"출력은 마크다운 없이 **순수 JSON 객체** 하나로만 응답합니다. 스키마는 아래와 같습니다:\\n\"\n",
        "    \"{\\n\"\n",
        "    '  \"edits\": [\\n'\n",
        "    '    {\"id\": \"<goal_id::filename>\", \"new_code\": \"<보강된 pytest 테스트 파일 전체 문자열>\"}\\n'\n",
        "    \"  ]\\n\"\n",
        "    \"}\\n\"\n",
        "    \"지침:\\n\"\n",
        "    \"• 테스트의 구조를 유지하되, 입력/경계조건/호출 순서/예외 트리거를 조정해 `still_missing_target_lines`에 실제로 도달하게 하세요.\\n\"\n",
        "    \"• 외부 부작용 금지(파일/네트워크/시간/환경/Temporal). 필요한 경우 monkeypatch/더미를 사용하세요.\\n\"\n",
        "    \"• import는 importlib + getattr 경로를 유지하고, 속성이 없을 때만 가드형 조건으로 pytest.skip을 허용합니다.\\n\"\n",
        "    \"• 각 테스트는 최소 1줄 이상의 target_lines를 실제 실행해야 하며, 관련된 assert 또는 pytest.raises를 포함해야 합니다.\\n\"\n",
        "    \"• 테스트 이름에 타격 라인을 `hits_L<line>` 형태로 포함하는 것을 권장합니다.\\n\"\n",
        "    \"• 출력에는 코드 외 설명/주석/마크다운을 포함하지 마세요. **JSON만** 반환하세요.\\n\"\n",
        ")\n",
        "\n",
        "with REFINE_PROMPTS.open(\"w\", encoding=\"utf-8\") as outf:\n",
        "    for i, batch in enumerate(batches, start=1):\n",
        "        user_payload = {\n",
        "            \"schema_version\": \"refine-v1\",\n",
        "            \"round_dir\": REFINE_DIR.name,\n",
        "            \"selection_params\": {\n",
        "                \"near_miss_window\": NEAR_MISS_WINDOW,\n",
        "                \"batch_size\": BATCH_SIZE,\n",
        "                \"using_coverage_gen_only\": True,\n",
        "                \"max_rounds\": MAX_ROUNDS\n",
        "            },\n",
        "            # ★ 전역 미커버 요약(모델이 우선순위 고려하도록 힌트)\n",
        "            \"global_uncovered\": {\n",
        "                \"total_missing_lines\": total_missing,\n",
        "                \"top_files\": global_uncovered_summary\n",
        "            },\n",
        "            \"batch_index\": i,\n",
        "            \"tests\": batch,\n",
        "        }\n",
        "        record = {\n",
        "            \"meta\": {\n",
        "                \"batch_index\": i,\n",
        "                \"num_tests\": len(batch),\n",
        "                \"ids\": [t[\"id\"] for t in batch],\n",
        "                \"round_dir\": REFINE_DIR.name,\n",
        "                \"using_coverage_gen_only\": True,\n",
        "            },\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_REFINE},\n",
        "                {\"role\": \"user\", \"content\": json.dumps(user_payload, ensure_ascii=False, indent=2)},\n",
        "            ],\n",
        "        }\n",
        "        outf.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# ==== 5) 요약/덤프 ====\n",
        "summary = {\n",
        "    \"round_dir\": REFINE_DIR.name,\n",
        "    \"using_coverage_gen_only\": True,\n",
        "    \"params\": {\n",
        "        \"near_miss_window\": NEAR_MISS_WINDOW,\n",
        "        \"batch_size\": BATCH_SIZE\n",
        "    },\n",
        "    \"selected\": len(selected),\n",
        "    \"batches\": [{\"batch_index\": i+1, \"num_tests\": len(b)} for i, b in enumerate(batches)],\n",
        "    \"global_uncovered\": {\n",
        "        \"total_missing_lines\": total_missing,\n",
        "        \"top_files\": global_uncovered_summary\n",
        "    }\n",
        "}\n",
        "REFINE_SUMMARY.write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "REFINE_TEST_EXPORT.write_text(json.dumps(selected, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ 보강 대상 선별 완료 (coverage_gen 기반 + 전역 분포 주입)\")\n",
        "print(\" - 라운드 폴더:\", REFINE_DIR)\n",
        "print(\" - 선별된 테스트 수:\", len(selected))\n",
        "print(\" - 배치 수:\", len(batches))\n",
        "print(\" - 프롬프트 JSONL:\", REFINE_PROMPTS)\n",
        "print(\" - 선별 요약:\", REFINE_SUMMARY)\n"
      ],
      "metadata": {
        "id": "8iTMUs3VPrke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd46dae4-5855-4235-d5bb-c952a68683fd"
      },
      "id": "8iTMUs3VPrke",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 보강 대상 선별 완료 (coverage_gen 기반 + 전역 분포 주입)\n",
            " - 라운드 폴더: /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5\n",
            " - 선별된 테스트 수: 8\n",
            " - 배치 수: 4\n",
            " - 프롬프트 JSONL: /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5/llm_refine_prompts.jsonl\n",
            " - 선별 요약: /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5/refine_selection.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-7) 보강 적용기 – LLM Edits 수신 → (교체형) 원본 백업 후 in-place 교체 + 활성 매니페스트 갱신\n",
        "import os, re, json, ast, shutil, time\n",
        "from pathlib import Path\n",
        "import httpx\n",
        "import backoff\n",
        "from openai import OpenAI, APIError, RateLimitError, APIConnectionError\n",
        "\n",
        "# ==== 설정 ====\n",
        "REPLACE_IN_PLACE = True   # ✅ 교체형 모드 (False면 _rN 파일로 공존 저장)\n",
        "MODEL = \"gpt-4o\"\n",
        "\n",
        "# ==== 경로/상수 ====\n",
        "assert 'PROJ' in globals(), \"3-0 단계를 먼저 실행하세요.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ / \"run_artifacts\" / \"run1\"\n",
        "GEN_DIR = PROJ / \"generated_tests\"\n",
        "\n",
        "# 최신 refine_roundN 탐색\n",
        "refine_rounds = sorted([p for p in ART_DIR.iterdir() if p.is_dir() and p.name.startswith(\"refine_round\")])\n",
        "if not refine_rounds:\n",
        "    raise SystemExit(\"refine_roundN 폴더가 없습니다. 3-6을 먼저 실행하세요.\")\n",
        "REFINE_DIR = refine_rounds[-1]\n",
        "PROMPTS_PATH = REFINE_DIR / \"llm_refine_prompts.jsonl\"\n",
        "\n",
        "if not PROMPTS_PATH.exists():\n",
        "    raise SystemExit(f\"프롬프트 파일이 없습니다: {PROMPTS_PATH}\")\n",
        "\n",
        "RAW_DIR = REFINE_DIR / \"_raw_edits\"\n",
        "ERR_DIR = REFINE_DIR / \"_errors\"\n",
        "ARCHIVE_DIR = REFINE_DIR / \"_archive\"\n",
        "LOG_PATH = REFINE_DIR / \"apply_log.jsonl\"\n",
        "MANIFEST = GEN_DIR / \"ACTIVE_MANIFEST.json\"\n",
        "\n",
        "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ERR_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "GEN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ==== OpenAI 클라이언트 ====\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise RuntimeError(\"OPENAI_API_KEY가 설정되지 않았습니다. 3-0 단계에서 .env를 로드했는지 확인하세요.\")\n",
        "http_client = httpx.Client(\n",
        "    timeout=180.0, follow_redirects=True,\n",
        "    limits=httpx.Limits(max_connections=1, max_keepalive_connections=0),\n",
        "    transport=httpx.HTTPTransport(retries=5),\n",
        ")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), base_url=\"https://api.openai.com/v1\", http_client=http_client)\n",
        "\n",
        "# ==== 유틸 ====\n",
        "def strip_fences(s: str) -> str:\n",
        "    import re\n",
        "    s = re.sub(r\"^```[a-zA-Z0-9]*\\s*\", \"\", (s or \"\").strip())\n",
        "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def write_error(tag: str, payload: dict):\n",
        "    (ERR_DIR / f\"{tag}.json\").write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def ensure_unique_path(base: Path) -> Path:\n",
        "    p = base; i = 2\n",
        "    while p.exists():\n",
        "        p = base.with_name(f\"{base.stem}_{i}{base.suffix}\"); i += 1\n",
        "    return p\n",
        "\n",
        "def now_ts():\n",
        "    return time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# ---- 검증 (모듈 무조건 skip 금지, 가드형만 허용) ----\n",
        "import re as _re, ast\n",
        "RE_IMPORTLIB = _re.compile(r\"\\bimportlib\\.import_module\\s*\\(\")\n",
        "RE_PYTEST_RAISES = _re.compile(r\"\\bpytest\\.raises\\s*\\(\")\n",
        "\n",
        "def parse_ast_or_error(code: str):\n",
        "    try: return ast.parse(code), None\n",
        "    except SyntaxError as e: return None, f\"syntax_error:{e.msg}@L{e.lineno}\"\n",
        "\n",
        "def extract_test_funcs(tree: ast.AST) -> list[ast.FunctionDef]:\n",
        "    return [n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef) and n.name.startswith(\"test_\")]\n",
        "\n",
        "def has_assert_or_raises(tree: ast.AST, code: str) -> bool:\n",
        "    return any(isinstance(n, ast.Assert) for n in ast.walk(tree)) or bool(RE_PYTEST_RAISES.search(code))\n",
        "\n",
        "def uses_importlib(code: str) -> bool:\n",
        "    return bool(RE_IMPORTLIB.search(code))\n",
        "\n",
        "def _parent_map(tree: ast.AST):\n",
        "    parent = {}\n",
        "    for node in ast.walk(tree):\n",
        "        for child in ast.iter_child_nodes(node):\n",
        "            parent[child] = node\n",
        "    return parent\n",
        "\n",
        "def _is_guarded_skip(call: ast.Call, parent_map) -> bool:\n",
        "    cur = call\n",
        "    while cur in parent_map:\n",
        "        cur = parent_map[cur]\n",
        "        if isinstance(cur, ast.If):\n",
        "            test = cur.test\n",
        "            if (isinstance(test, ast.Compare) and len(test.ops)==1 and isinstance(test.ops[0], ast.Is)\n",
        "                and len(test.comparators)==1 and isinstance(test.comparators[0], ast.Constant)\n",
        "                and test.comparators[0].value is None):\n",
        "                return True\n",
        "        if isinstance(cur, ast.ExceptHandler):\n",
        "            t = cur.type\n",
        "            if isinstance(t, ast.Name) and t.id in {\"ImportError\",\"NameError\"}: return True\n",
        "            if isinstance(t, ast.Tuple) and any(isinstance(e, ast.Name) and e.id in {\"ImportError\",\"NameError\"} for e in t.elts):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "def has_unconditional_skip(code: str) -> tuple[bool, list[int]]:\n",
        "    try:\n",
        "        tree = ast.parse(code)\n",
        "    except SyntaxError:\n",
        "        return (False, [])\n",
        "    parent = _parent_map(tree); bad = []\n",
        "    for node in ast.walk(tree):\n",
        "        if isinstance(node, ast.Call):\n",
        "            f = node.func\n",
        "            if isinstance(f, ast.Attribute) and isinstance(f.value, ast.Name) and f.value.id==\"pytest\" and f.attr==\"skip\":\n",
        "                if not _is_guarded_skip(node, parent): bad.append(getattr(node, \"lineno\", -1))\n",
        "    return (len(bad) > 0), bad\n",
        "\n",
        "def minimal_viability_checks(code: str) -> tuple[bool, list[str], dict]:\n",
        "    reasons = []; meta = {\"warnings\": []}\n",
        "    if len((code or \"\").strip()) < 60:\n",
        "        reasons.append(\"too_short\")\n",
        "    tree, synerr = parse_ast_or_error(code)\n",
        "    if synerr: reasons.append(synerr); return False, reasons, meta\n",
        "    tests = extract_test_funcs(tree)\n",
        "    if not tests: reasons.append(\"no_test_functions\")\n",
        "    if not has_assert_or_raises(tree, code): reasons.append(\"no_assert_or_raises\")\n",
        "    if not uses_importlib(code): reasons.append(\"no_importlib_import_module\")\n",
        "    if tests and not any(\"hits_L\" in t.name for t in tests):\n",
        "        meta[\"warnings\"].append(\"missing_hits_L_in_test_name\")\n",
        "    bad_skip, lines = has_unconditional_skip(code)\n",
        "    if bad_skip: reasons.append(f\"unconditional_skip_detected@{lines}\")\n",
        "    return (len(reasons) == 0), reasons, meta\n",
        "\n",
        "# ==== OpenAI 호출 ====\n",
        "@backoff.on_exception(backoff.expo, (APIConnectionError, APIError, RateLimitError), max_tries=8, max_time=300)\n",
        "def call_openai_with_retry(messages):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=messages,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        timeout=180.0,\n",
        "    )\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "# ==== 활성 매니페스트 ====\n",
        "def load_manifest():\n",
        "    try:\n",
        "        return json.loads(MANIFEST.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        return {\"active\": {}, \"history\": {}}\n",
        "def save_manifest(m):\n",
        "    MANIFEST.write_text(json.dumps(m, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "manifest = load_manifest()\n",
        "\n",
        "# ==== 메인 루프 ====\n",
        "ok_batches = ok_edits = fail_batches = fail_edits = 0\n",
        "\n",
        "with PROMPTS_PATH.open(\"r\", encoding=\"utf-8\") as f_in, open(LOG_PATH, \"w\", encoding=\"utf-8\") as f_log:\n",
        "    for line in f_in:\n",
        "        rec = json.loads(line)\n",
        "        meta = rec.get(\"meta\", {})\n",
        "        messages = rec.get(\"messages\", [])\n",
        "        bidx = meta.get(\"batch_index\")\n",
        "\n",
        "        print(f\"\\n🚀 Refinement Batch #{bidx} 요청…\")\n",
        "        try:\n",
        "            out_text = call_openai_with_retry(messages)\n",
        "        except Exception as e:\n",
        "            fail_batches += 1\n",
        "            write_error(f\"batch_{bidx}_request_error\", {\"error\": str(e)})\n",
        "            print(f\"❌ 배치 {bidx} 요청 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 원문 저장\n",
        "        (RAW_DIR / f\"batch_{bidx}_raw.json\").write_text(out_text, encoding=\"utf-8\")\n",
        "\n",
        "        # JSON 파싱\n",
        "        try:\n",
        "            cleaned = strip_fences(out_text)\n",
        "            result = json.loads(cleaned)\n",
        "        except Exception as e:\n",
        "            fail_batches += 1\n",
        "            write_error(f\"batch_{bidx}_json_error\", {\"error\": str(e), \"raw_head\": out_text[:2000]})\n",
        "            print(f\"❌ 배치 {bidx} JSON 파싱 실패: {e}\")\n",
        "            continue\n",
        "\n",
        "        edits = result.get(\"edits\") or []\n",
        "        if not isinstance(edits, list) or not edits:\n",
        "            fail_batches += 1\n",
        "            write_error(f\"batch_{bidx}_schema_error\", {\"result\": result})\n",
        "            print(f\"❌ 배치 {bidx} 스키마 오류: edits 비어있음\")\n",
        "            continue\n",
        "\n",
        "        saved = []\n",
        "        for eidx, e in enumerate(edits, start=1):\n",
        "            eid = e.get(\"id\", \"\")\n",
        "            code = strip_fences(e.get(\"new_code\", \"\"))\n",
        "\n",
        "            if \"::\" not in eid:\n",
        "                fail_edits += 1\n",
        "                write_error(f\"batch_{bidx}_edit_{eidx}_bad_id\", {\"id\": eid})\n",
        "                print(f\"⚠️ 편집 #{eidx} 제외: 잘못된 id 형식\")\n",
        "                continue\n",
        "            gid, orig_name = eid.split(\"::\", 1)\n",
        "            orig_name = Path(orig_name).name\n",
        "\n",
        "            ok_min, reasons, meta_w = minimal_viability_checks(code)\n",
        "            if not ok_min:\n",
        "                fail_edits += 1\n",
        "                write_error(f\"batch_{bidx}_edit_{eidx}_min_viability\", {\"id\": eid, \"reasons\": reasons, **meta_w})\n",
        "                print(f\"⚠️ 편집 #{eidx} 제외: {reasons}\")\n",
        "                continue\n",
        "\n",
        "            # === 저장 정책 ===\n",
        "            round_tag = REFINE_DIR.name.rsplit(\"refine_round\", 1)[-1]\n",
        "            stem = Path(orig_name).stem\n",
        "            suffix = Path(orig_name).suffix or \".py\"\n",
        "\n",
        "            if REPLACE_IN_PLACE:\n",
        "                # 1) 기존 파일 백업\n",
        "                dst_path = GEN_DIR / orig_name\n",
        "                if dst_path.exists():\n",
        "                    backup = ARCHIVE_DIR / f\"{now_ts()}__{orig_name}\"\n",
        "                    shutil.copy2(dst_path, backup)\n",
        "                    # history 기록\n",
        "                    manifest.setdefault(\"history\", {}).setdefault(gid, []).append(str(backup))\n",
        "\n",
        "                # 2) 원래 경로에 새 코드로 교체\n",
        "                dst_path.write_text(code, encoding=\"utf-8\")\n",
        "                saved.append(dst_path.name)\n",
        "\n",
        "                # 3) active 매핑 갱신\n",
        "                manifest.setdefault(\"active\", {})[gid] = dst_path.name\n",
        "            else:\n",
        "                # 공존 저장(_rN)\n",
        "                out_name = f\"{stem}_r{round_tag}{suffix}\"\n",
        "                out_path = ensure_unique_path(GEN_DIR / out_name)\n",
        "                out_path.write_text(code, encoding=\"utf-8\")\n",
        "                saved.append(out_path.name)\n",
        "                # active는 최신본으로 포인터만 갱신\n",
        "                manifest.setdefault(\"active\", {})[gid] = out_path.name\n",
        "                manifest.setdefault(\"history\", {}).setdefault(gid, []).append(str(out_path))\n",
        "\n",
        "            ok_edits += 1\n",
        "            print(f\"✅ 적용: {manifest['active'][gid]} (warnings: {','.join(meta_w.get('warnings', [])) or '없음'})\")\n",
        "\n",
        "        if saved:\n",
        "            ok_batches += 1\n",
        "            save_manifest(manifest)\n",
        "            f_log.write(json.dumps({\"batch_index\": bidx, \"saved_files\": saved}, ensure_ascii=False) + \"\\n\")\n",
        "        else:\n",
        "            fail_batches += 1\n",
        "            write_error(f\"batch_{bidx}_no_valid_edits\", {\"note\": \"모든 edits가 검증에서 제외됨\"})\n",
        "\n",
        "print(f\"\\n✅ 보강 적용 완료: 배치 성공 {ok_batches} / 실패 {fail_batches} | 편집 성공 {ok_edits} / 실패 {fail_edits}\")\n",
        "print(f\"   • 라운드 폴더 : {REFINE_DIR}\")\n",
        "print(f\"   • 원문       : {RAW_DIR}\")\n",
        "print(f\"   • 에러       : {ERR_DIR}\")\n",
        "print(f\"   • 로그       : {LOG_PATH}\")\n",
        "print(f\"   • 활성 매니페스트 : {MANIFEST}\")\n",
        "print(\"이제 3-8을 실행해 커버리지/목표 달성률 향상을 평가하세요.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG9UvvirgIsY",
        "outputId": "7ea1a89e-a87a-4415-a3f3-2d9b09fff9c8"
      },
      "id": "sG9UvvirgIsY",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Refinement Batch #1 요청…\n",
            "✅ 적용: test_0001_test_gen_0001_banking_service_deposit_py_2.py (warnings: 없음)\n",
            "✅ 적용: test_0004_test_gen_0004_activities_refund_py_2.py (warnings: 없음)\n",
            "✅ 적용: test_0005_test_gen_0005_run_workflow_main_py_2.py (warnings: 없음)\n",
            "\n",
            "🚀 Refinement Batch #2 요청…\n",
            "✅ 적용: test_gen_0006_banking_service_deposit_that_fails.py (warnings: 없음)\n",
            "✅ 적용: test_0007_test_gen_0007_activities_deposit_py_2.py (warnings: 없음)\n",
            "\n",
            "🚀 Refinement Batch #3 요청…\n",
            "✅ 적용: test_0008_test_gen_0008_activities_deposit_py_2.py (warnings: 없음)\n",
            "\n",
            "🚀 Refinement Batch #4 요청…\n",
            "✅ 적용: test_0009_test_gen_0009_activities_refund_py_2.py (warnings: 없음)\n",
            "✅ 적용: test_gen_0010_run_workflow_main.py (warnings: 없음)\n",
            "\n",
            "✅ 보강 적용 완료: 배치 성공 4 / 실패 0 | 편집 성공 8 / 실패 0\n",
            "   • 라운드 폴더 : /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5\n",
            "   • 원문       : /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5/_raw_edits\n",
            "   • 에러       : /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5/_errors\n",
            "   • 로그       : /content/money-transfer-project-template-python/run_artifacts/run1/refine_round5/apply_log.jsonl\n",
            "   • 활성 매니페스트 : /content/money-transfer-project-template-python/generated_tests/ACTIVE_MANIFEST.json\n",
            "이제 3-8을 실행해 커버리지/목표 달성률 향상을 평가하세요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-8) 기존 tests + 생성/보강 tests 격리 실행 · 로그 수집 · 샤드 결합 · 향상치 계산 (ACTIVE_MANIFEST 우선)\n",
        "import os, sys, json, re, time, subprocess, shutil, shlex\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "from lxml import etree\n",
        "\n",
        "# ==== 경로/상수 ====\n",
        "assert 'PROJ' in globals(), \"3-0 단계를 먼저 실행하세요.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ / \"run_artifacts\" / \"run1\"\n",
        "GEN_DIR = PROJ / \"generated_tests\"\n",
        "TESTS_DIR = PROJ / \"tests\"\n",
        "LOG_DIR = ART_DIR / \"logs\"\n",
        "COV_SHARDS_DIR = ART_DIR / \"cov_shards\"\n",
        "HTML_DIR_GEN = PROJ / \"htmlcov_gen\"\n",
        "ACTIVE_MANIFEST = GEN_DIR / \"ACTIVE_MANIFEST.json\"\n",
        "\n",
        "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
        "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "COV_SHARDS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "HTML_DIR_GEN.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RCFILE = PROJ / \".coveragerc\"\n",
        "rc_opt = f\" --rcfile {RCFILE}\" if RCFILE.exists() else \"\"\n",
        "\n",
        "# 실행 파라미터\n",
        "PY_EXE = sys.executable\n",
        "TIMEOUT_SEC_GEN = 30\n",
        "TIMEOUT_SEC_BASE = 120\n",
        "PYTEST_FLAGS = \"-q -s\"\n",
        "ENV_BASE = os.environ.copy()\n",
        "ENV_BASE.setdefault(\"NO_PROXY\", \"*\")\n",
        "ENV_BASE.setdefault(\"PYTHONHASHSEED\", \"0\")\n",
        "\n",
        "# 선택 정책 플래그(매니페스트 없을 때만 사용)\n",
        "PREFER_LATEST_REFINED = True\n",
        "KEEP_ORIGINAL_ALONGSIDE = False\n",
        "\n",
        "# goal_id / refine suffix\n",
        "RE_GOAL = re.compile(r\"(?:^|[_-])(?P<gid>\\d{4})(?:[_-]|$)\")\n",
        "RE_REFINE_SUFFIX = re.compile(r\"_r(\\d+)\\.py$\")\n",
        "\n",
        "def goal_id_from_name(name: str) -> str | None:\n",
        "    m = RE_GOAL.search(name); return m.group(\"gid\") if m else None\n",
        "\n",
        "def sh(cmd: str, cwd: Path|None=None, timeout: int|None=None, env: dict|None=None):\n",
        "    try:\n",
        "        p = subprocess.run(cmd, cwd=str(cwd or PROJ), env=env or ENV_BASE,\n",
        "                           shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
        "                           timeout=timeout, text=True)\n",
        "        return p.returncode, p.stdout, p.stderr, False\n",
        "    except subprocess.TimeoutExpired as e:\n",
        "        return 124, e.stdout or \"\", e.stderr or \"\", True\n",
        "\n",
        "def rel_to_proj(p: Path) -> str:\n",
        "    try: return str(p.resolve().relative_to(PROJ))\n",
        "    except Exception: return str(p.resolve())\n",
        "\n",
        "def latest_refine_round() -> int|None:\n",
        "    rounds = []\n",
        "    for d in ART_DIR.iterdir():\n",
        "        if d.is_dir() and d.name.startswith(\"refine_round\"):\n",
        "            try: rounds.append(int(d.name.replace(\"refine_round\",\"\")))\n",
        "            except: pass\n",
        "    return max(rounds) if rounds else None\n",
        "\n",
        "def list_from_active_manifest() -> list[Path]:\n",
        "    try:\n",
        "        m = json.loads(ACTIVE_MANIFEST.read_text(encoding=\"utf-8\"))\n",
        "        active = m.get(\"active\", {})\n",
        "        files = [GEN_DIR / fname for fname in active.values()]\n",
        "        files = [p for p in files if p.exists() and p.suffix==\".py\"]\n",
        "        if files:\n",
        "            print(f\"📒 ACTIVE_MANIFEST 사용: {len(files)}개 활성 테스트 실행\")\n",
        "        return sorted(files)\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def list_generated_test_files_selected() -> list[Path]:\n",
        "    # 매니페스트가 있으면 그걸 우선 사용\n",
        "    from_manifest = list_from_active_manifest()\n",
        "    if from_manifest:\n",
        "        return from_manifest\n",
        "\n",
        "    # 없으면: 최신 refine 라운드의 *_rN.py만 선택(없으면 원본)\n",
        "    if not GEN_DIR.exists(): return []\n",
        "    files = sorted([p for p in GEN_DIR.glob(\"*.py\") if p.is_file()])\n",
        "    if not files: return []\n",
        "\n",
        "    latest = latest_refine_round()\n",
        "    def base_stem(p: Path):\n",
        "        m = RE_REFINE_SUFFIX.search(p.name)\n",
        "        return p.name[:m.start()] if m else p.stem\n",
        "\n",
        "    selected, by_stem = [], {}\n",
        "    for f in files:\n",
        "        by_stem.setdefault(base_stem(f), []).append(f)\n",
        "\n",
        "    refined_count = original_kept = original_dropped = 0\n",
        "    for stem, group in by_stem.items():\n",
        "        best_refined, best_round, originals = None, -1, []\n",
        "        for f in group:\n",
        "            m = RE_REFINE_SUFFIX.search(f.name)\n",
        "            if m:\n",
        "                r = int(m.group(1))\n",
        "                if latest is None or r == latest:\n",
        "                    if r > best_round:\n",
        "                        best_round, best_refined = r, f\n",
        "            else:\n",
        "                originals.append(f)\n",
        "        if PREFER_LATEST_REFINED and best_refined is not None:\n",
        "            selected.append(best_refined); refined_count += 1\n",
        "            if KEEP_ORIGINAL_ALONGSIDE:\n",
        "                selected.extend(originals); original_kept += len(originals)\n",
        "            else:\n",
        "                original_dropped += len(originals)\n",
        "        else:\n",
        "            selected.extend(group)\n",
        "    print(f\"📌 선택 요약: 보강본 {refined_count}개 선택\"\n",
        "          + (f\", 원본 추가 {original_kept}개\" if KEEP_ORIGINAL_ALONGSIDE else f\", 원본 제외 {original_dropped}개\"))\n",
        "    return sorted(selected)\n",
        "\n",
        "# ==== 0) 산출물 경로 ====\n",
        "results_jsonl = ART_DIR / \"results.jsonl\"\n",
        "manifest_path = ART_DIR / \"manifest.json\"\n",
        "coverage_json_path = ART_DIR / \"coverage_gen.json\"\n",
        "coverage_xml_path  = ART_DIR / \"coverage_gen.xml\"\n",
        "\n",
        "for old in [results_jsonl, coverage_json_path, coverage_xml_path]:\n",
        "    if old.exists():\n",
        "        old.unlink()\n",
        "\n",
        "runs = []; ok=fail=to_cnt=0\n",
        "\n",
        "# ==== 1) 기존 tests/ 한 번 실행 → 베이스라인 샤드 ====\n",
        "if TESTS_DIR.exists() and any(TESTS_DIR.glob(\"test*.py\")):\n",
        "    shard_base = COV_SHARDS_DIR / \".coverage.__baseline_tests__\"\n",
        "    env = ENV_BASE.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{PROJ}:{env.get('PYTHONPATH','')}\"\n",
        "    env[\"COVERAGE_FILE\"] = str(shard_base)\n",
        "    target = rel_to_proj(TESTS_DIR)\n",
        "    cmd = f\"{PY_EXE} -m coverage run{rc_opt} -m pytest {PYTEST_FLAGS} {shlex.quote(target)}\"\n",
        "    start = time.time()\n",
        "    ts_start = datetime.now(timezone.utc).isoformat()\n",
        "    rc, out, err, timed_out = sh(cmd, cwd=PROJ, timeout=TIMEOUT_SEC_BASE, env=env)\n",
        "    dur = round(time.time()-start, 3)\n",
        "    ts_end = datetime.now(timezone.utc).isoformat()\n",
        "    (LOG_DIR / \"__baseline_tests__.out.txt\").write_text(out, encoding=\"utf-8\")\n",
        "    (LOG_DIR / \"__baseline_tests__.err.txt\").write_text(err, encoding=\"utf-8\")\n",
        "    runs.append({\"test_file\":\"__BASELINE_SUITE__\",\"goal_id\":None,\n",
        "                 \"start_utc\":ts_start,\"end_utc\":ts_end,\"duration_sec\":dur,\n",
        "                 \"returncode\":rc,\"timed_out\":timed_out,\n",
        "                 \"stdout_len\":len(out),\"stderr_len\":len(err),\n",
        "                 \"shard_path\":str(shard_base),\"invoked_path\":target})\n",
        "    if timed_out: to_cnt+=1; print(f\"⏱️ TIMEOUT __BASELINE_SUITE__ ({dur}s)\")\n",
        "    elif rc==0: ok+=1; print(f\"✅ PASS   __BASELINE_SUITE__ ({dur}s)\")\n",
        "    else:\n",
        "        fail+=1; first_err=(err.strip().splitlines() or [\"\"])[0]\n",
        "        print(f\"❌ FAIL   __BASELINE_SUITE__ (rc={rc}, {dur}s) :: {first_err}\")\n",
        "else:\n",
        "    print(\"ℹ️ tests/ 폴더 또는 파일이 없어 베이스라인 개별 실행 건너뜀.\")\n",
        "\n",
        "# ==== 2) 생성/보강 테스트 개별 격리 실행 ====\n",
        "test_files = list_generated_test_files_selected()\n",
        "print(f\"🧪 생성/보강 테스트 파일(실행 대상): {len(test_files)}개\")\n",
        "if not test_files:\n",
        "    print(\"⚠️ 실행할 생성/보강 테스트가 없습니다.\")\n",
        "\n",
        "for tf in test_files:\n",
        "    name = tf.name\n",
        "    gid = goal_id_from_name(name) or \"----\"\n",
        "    shard = COV_SHARDS_DIR / f\".coverage.{name}\"\n",
        "\n",
        "    env = ENV_BASE.copy()\n",
        "    env[\"PYTHONPATH\"] = f\"{PROJ}:{env.get('PYTHONPATH','')}\"\n",
        "    env[\"COVERAGE_FILE\"] = str(shard)\n",
        "\n",
        "    target = rel_to_proj(tf)\n",
        "    cmd = f\"{PY_EXE} -m coverage run{rc_opt} -m pytest {PYTEST_FLAGS} {shlex.quote(target)}\"\n",
        "    start = time.time()\n",
        "    ts_start = datetime.now(timezone.utc).isoformat()\n",
        "    rc, out, err, timed_out = sh(cmd, cwd=PROJ, timeout=TIMEOUT_SEC_GEN, env=env)\n",
        "    dur = round(time.time()-start, 3)\n",
        "    ts_end = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    (LOG_DIR / f\"{name}.out.txt\").write_text(out, encoding=\"utf-8\")\n",
        "    (LOG_DIR / f\"{name}.err.txt\").write_text(err, encoding=\"utf-8\")\n",
        "\n",
        "    runs.append({\"test_file\":name,\"goal_id\":gid,\n",
        "                 \"start_utc\":ts_start,\"end_utc\":ts_end,\"duration_sec\":dur,\n",
        "                 \"returncode\":rc,\"timed_out\":timed_out,\n",
        "                 \"stdout_len\":len(out),\"stderr_len\":len(err),\n",
        "                 \"shard_path\":str(shard),\"invoked_path\":target})\n",
        "    if timed_out: to_cnt+=1; print(f\"⏱️ TIMEOUT {name} ({dur}s)\")\n",
        "    elif rc==0: ok+=1; print(f\"✅ PASS   {name} ({dur}s)\")\n",
        "    else:\n",
        "        fail+=1; first_err=(err.strip().splitlines() or [\"\"])[0]\n",
        "        print(f\"❌ FAIL   {name} (rc={rc}, {dur}s) :: {first_err}\")\n",
        "\n",
        "with results_jsonl.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    for r in runs: f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "manifest = {\n",
        "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"project\": str(PROJ),\n",
        "    \"run_dir\": str(ART_DIR),\n",
        "    \"tests_total\": (len(test_files) + (1 if any(x['test_file']==\"__BASELINE_SUITE__\" for x in runs) else 0)),\n",
        "    \"pass\": ok, \"fail\": fail, \"timeout\": to_cnt,\n",
        "    \"logs_dir\": str(LOG_DIR),\n",
        "    \"cov_shards_dir\": str(COV_SHARDS_DIR),\n",
        "    \"active_manifest_used\": ACTIVE_MANIFEST.exists()\n",
        "}\n",
        "manifest_path.write_text(json.dumps(manifest, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"\\n📦 실행 요약:\", json.dumps({\"pass\": ok, \"fail\": fail, \"timeout\": to_cnt, \"total\": manifest['tests_total']}, ensure_ascii=False))\n",
        "\n",
        "# ==== 3) 커버리지 결합(JSON/XML/HTML) ====\n",
        "shards = sorted([p for p in COV_SHARDS_DIR.iterdir() if p.name.startswith(\".coverage.\")])\n",
        "if not shards:\n",
        "    print(\"⚠️ 커버리지 샤드가 없습니다. 테스트가 즉시 실패했을 가능성이 있습니다.\")\n",
        "else:\n",
        "    subprocess.call(f\"coverage erase{rc_opt}\", shell=True, cwd=str(PROJ))\n",
        "    combine_cmd = \"coverage combine\" + rc_opt + \" \" + \" \".join(shlex.quote(str(p)) for p in shards)\n",
        "    print(\"> \", combine_cmd)\n",
        "    subprocess.call(combine_cmd, shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage json -o {coverage_json_path.name}{rc_opt}\", shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage xml  -o {coverage_xml_path.name}{rc_opt}\",  shell=True, cwd=str(PROJ))\n",
        "    subprocess.call(f\"coverage html -d {HTML_DIR_GEN.name}{rc_opt}\",       shell=True, cwd=str(PROJ))\n",
        "    # 보관\n",
        "    src_json = PROJ / coverage_json_path.name\n",
        "    src_xml  = PROJ / coverage_xml_path.name\n",
        "    if src_json.exists(): shutil.copy2(src_json, coverage_json_path)\n",
        "    if src_xml.exists():  shutil.copy2(src_xml,  coverage_xml_path)\n",
        "    print(\"✅ 커버리지 결합 완료\")\n",
        "    print(\" - JSON :\", coverage_json_path)\n",
        "    print(\" - XML  :\", coverage_xml_path)\n",
        "    print(\" - HTML :\", HTML_DIR_GEN / \"index.html\")\n",
        "\n",
        "# ==== 4) 분기 관측/목표 달성률 ====\n",
        "observed_outcomes_gen = {}; branch_points=full_hit=half_hit=zero_hit=0\n",
        "if coverage_xml_path.exists():\n",
        "    try:\n",
        "        xml_root = etree.parse(str(coverage_xml_path)).getroot()\n",
        "        for cls in xml_root.findall(\".//class\"):\n",
        "            filename = cls.get(\"filename\") or \"\"\n",
        "            if not filename: continue\n",
        "            abs_path = (PROJ / filename).resolve() if not Path(filename).is_absolute() else Path(filename)\n",
        "            for line in cls.findall(\"./lines/line\"):\n",
        "                if line.get(\"branch\") != \"true\": continue\n",
        "                try: num = int(line.get(\"number\"))\n",
        "                except: continue\n",
        "                cond = line.get(\"condition-coverage\")\n",
        "                covered = total = 0\n",
        "                if cond:\n",
        "                    m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", cond)\n",
        "                    if m: covered, total = int(m.group(1)), int(m.group(2))\n",
        "                if total == 0: continue\n",
        "                observed_outcomes_gen.setdefault(str(abs_path), {})[num] = {\n",
        "                    \"covered\": covered, \"total\": total, \"ratio\": round(covered/total, 3)\n",
        "                }\n",
        "                branch_points += 1\n",
        "                if covered == 0: zero_hit += 1\n",
        "                elif covered == total: full_hit += 1\n",
        "                else: half_hit += 1\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ coverage_xml 파싱 실패:\", e)\n",
        "\n",
        "(ART_DIR / \"observed_outcomes_gen.json\").write_text(\n",
        "    json.dumps(observed_outcomes_gen, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
        ")\n",
        "print(f\"🧮 분기 관측 요약 → total:{branch_points}, full:{full_hit}, half:{half_hit}, zero:{zero_hit}\")\n",
        "\n",
        "# ==== 5) 목표 달성률 ====\n",
        "GOALS_FILE = ART_DIR / \"goals_ranked.json\"\n",
        "if GOALS_FILE.exists() and coverage_json_path.exists():\n",
        "    cov_json = json.loads((coverage_json_path).read_text(encoding=\"utf-8\"))\n",
        "    files_map = cov_json.get(\"files\", {})\n",
        "    def line_hit(fpath: str, ln: int) -> bool:\n",
        "        finfo = files_map.get(fpath) or files_map.get(str(Path(fpath).resolve()))\n",
        "        if not finfo: return False\n",
        "        executed = set(finfo.get(\"executed_lines\", []) or [])\n",
        "        return ln in executed\n",
        "    goals = json.loads(GOALS_FILE.read_text(encoding=\"utf-8\"))\n",
        "    goal_stats = []\n",
        "    for g in goals:\n",
        "        f = g[\"file\"]; abs1 = str((PROJ / f).resolve()); abs2 = f\n",
        "        hit = sum(1 for ln in g.get(\"target_lines\", []) if line_hit(abs1, ln) or line_hit(abs2, ln))\n",
        "        total = len(g.get(\"target_lines\", [])) or 1\n",
        "        goal_stats.append({\"id\": g[\"id\"], \"hit\": hit, \"total\": total, \"rate\": round(hit/total, 3)})\n",
        "    (ART_DIR / \"goal_achievements.json\").write_text(\n",
        "        json.dumps(goal_stats, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
        "    )\n",
        "    hit_goals = sum(1 for s in goal_stats if s[\"hit\"] > 0)\n",
        "    print(f\"🎯 목표 달성률: {hit_goals}/{len(goal_stats)} 목표가 ≥1 라인 도달\")\n",
        "\n",
        "# ==== 6) 라인/브랜치 커버리지 요약 + 베이스 대비 델타 ====\n",
        "def load_json(p: Path, default=None):\n",
        "    try: return json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "    except Exception: return default\n",
        "\n",
        "base = load_json(ART_DIR / \"coverage_base.json\", {\"files\": {}}) or {\"files\": {}}\n",
        "gen  = load_json(coverage_json_path, {\"files\": {}}) or {\"files\": {}}\n",
        "base_files = base.get(\"files\", {}); gen_files = gen.get(\"files\", {})\n",
        "\n",
        "def _sum_len(key, d):\n",
        "    return sum(len((d.get(f, {}) or {}).get(key, []) or []) for f in d.keys())\n",
        "\n",
        "base_exec = _sum_len(\"executed_lines\", base_files)\n",
        "base_miss = _sum_len(\"missing_lines\",  base_files)\n",
        "gen_exec  = _sum_len(\"executed_lines\", gen_files)\n",
        "gen_miss  = _sum_len(\"missing_lines\",  gen_files)\n",
        "\n",
        "def pct(a, b): return (100.0 * a / b) if b else 0.0\n",
        "line_total_base = base_exec + base_miss\n",
        "line_total_gen  = gen_exec + gen_miss\n",
        "\n",
        "# 브랜치 합계는 XML에서 집계\n",
        "def compute_branch_totals(xml_path: Path):\n",
        "    if not xml_path.exists(): return (0,0)\n",
        "    total = covered = 0\n",
        "    try:\n",
        "        root = etree.parse(str(xml_path)).getroot()\n",
        "        for line in root.findall(\".//line[@branch='true']\"):\n",
        "            cond = line.get(\"condition-coverage\")\n",
        "            if not cond: continue\n",
        "            m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", cond)\n",
        "            if not m: continue\n",
        "            c, t = int(m.group(1)), int(m.group(2))\n",
        "            covered += c; total += t\n",
        "    except Exception:\n",
        "        pass\n",
        "    return covered, total\n",
        "\n",
        "br_cov, br_tot = compute_branch_totals(coverage_xml_path)\n",
        "\n",
        "delta = {\n",
        "    \"executed_lines_delta\": gen_exec - base_exec,\n",
        "    \"missing_lines_delta\":  base_miss - gen_miss,  # +면 미싱 감소\n",
        "    \"base_executed\": base_exec, \"gen_executed\": gen_exec,\n",
        "    \"base_missing\":  base_miss, \"gen_missing\":  gen_miss,\n",
        "    \"line_pct_base\": round(pct(base_exec, line_total_base), 2),\n",
        "    \"line_pct_gen\":  round(pct(gen_exec,  line_total_gen),  2),\n",
        "    \"branch_cov_gen\": round(pct(br_cov, br_tot), 2) if br_tot else 0.0,\n",
        "    \"branch_hits_gen\": br_cov, \"branch_total_gen\": br_tot\n",
        "}\n",
        "(ART_DIR / \"coverage_delta.json\").write_text(json.dumps(delta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "(ART_DIR / \"coverage_summary.json\").write_text(json.dumps(delta, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"📈 베이스라인 대비 향상치/요약:\", json.dumps(delta, ensure_ascii=False))\n",
        "\n",
        "print(\"✅ 3-8 완료: (기존 + 활성 생성/보강) 격리 실행/샤드 결합/분기·목표·라인·브랜치 요약 산출\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NPVswdai70B",
        "outputId": "686c6fd9-f251-40bf-f33d-ae07c8735387"
      },
      "id": "-NPVswdai70B",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PASS   __BASELINE_SUITE__ (14.416s)\n",
            "📒 ACTIVE_MANIFEST 사용: 9개 활성 테스트 실행\n",
            "🧪 생성/보강 테스트 파일(실행 대상): 9개\n",
            "✅ PASS   test_0001_test_gen_0001_banking_service_deposit_py_2.py (13.883s)\n",
            "❌ FAIL   test_0002_test_gen_0002_run_worker_module_py_2.py (rc=1, 13.862s) :: \n",
            "✅ PASS   test_0004_test_gen_0004_activities_refund_py_2.py (12.992s)\n",
            "❌ FAIL   test_0005_test_gen_0005_run_workflow_main_py_2.py (rc=1, 13.532s) :: \n",
            "✅ PASS   test_0007_test_gen_0007_activities_deposit_py_2.py (13.031s)\n",
            "❌ FAIL   test_0008_test_gen_0008_activities_deposit_py_2.py (rc=5, 13.083s) :: \n",
            "❌ FAIL   test_0009_test_gen_0009_activities_refund_py_2.py (rc=2, 13.24s) :: \n",
            "❌ FAIL   test_gen_0006_banking_service_deposit_that_fails.py (rc=5, 12.633s) :: \n",
            "❌ FAIL   test_gen_0010_run_workflow_main.py (rc=1, 13.672s) :: \n",
            "\n",
            "📦 실행 요약: {\"pass\": 4, \"fail\": 6, \"timeout\": 0, \"total\": 10}\n",
            ">  coverage combine --rcfile /content/money-transfer-project-template-python/.coveragerc /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.__baseline_tests__ /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0001_test_gen_0001_banking_service_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0002_test_gen_0002_run_worker_module_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0004_test_gen_0004_activities_refund_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0005_test_gen_0005_run_workflow_main_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0007_test_gen_0007_activities_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0008_test_gen_0008_activities_deposit_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_0009_test_gen_0009_activities_refund_py_2.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_gen_0006_banking_service_deposit_that_fails.py /content/money-transfer-project-template-python/run_artifacts/run1/cov_shards/.coverage.test_gen_0010_run_workflow_main.py\n",
            "✅ 커버리지 결합 완료\n",
            " - JSON : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_gen.json\n",
            " - XML  : /content/money-transfer-project-template-python/run_artifacts/run1/coverage_gen.xml\n",
            " - HTML : /content/money-transfer-project-template-python/htmlcov_gen/index.html\n",
            "🧮 분기 관측 요약 → total:5, full:3, half:2, zero:0\n",
            "🎯 목표 달성률: 2/10 목표가 ≥1 라인 도달\n",
            "📈 베이스라인 대비 향상치/요약: {\"executed_lines_delta\": 15, \"missing_lines_delta\": 15, \"base_executed\": 102, \"gen_executed\": 117, \"base_missing\": 54, \"gen_missing\": 39, \"line_pct_base\": 65.38, \"line_pct_gen\": 75.0, \"branch_cov_gen\": 80.0, \"branch_hits_gen\": 8, \"branch_total_gen\": 10}\n",
            "✅ 3-8 완료: (기존 + 활성 생성/보강) 격리 실행/샤드 결합/분기·목표·라인·브랜치 요약 산출\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3-9) 최종 비교 – PyTest(베이스라인) vs 본 연구(3-8 최종 산출 직접 사용) + 모듈별 리포트\n",
        "import os, sys, json, re, subprocess, shlex, shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timezone\n",
        "from lxml import etree\n",
        "\n",
        "# ===== 경로/상수 =====\n",
        "assert 'PROJ' in globals(), \"3-0 단계를 먼저 실행하세요.\"\n",
        "PROJ = Path(PROJ).resolve()\n",
        "ART_DIR = PROJ / \"run_artifacts\" / \"run1\"\n",
        "GEN_DIR = PROJ / \"generated_tests\"\n",
        "TESTS_DIR = PROJ / \"tests\"\n",
        "LOG_DIR = ART_DIR / \"logs\"\n",
        "\n",
        "HTML_DIR_BASE = PROJ / \"htmlcov_pytest\"         # pytest 단독 HTML\n",
        "HTML_DIR_OUR  = PROJ / \"htmlcov_our\"            # 본 연구 HTML (리플레이 모드 시)\n",
        "HTML_DIR_38   = PROJ / \"htmlcov_gen\"            # 3-8 HTML 디렉터리(직접사용 모드)\n",
        "\n",
        "RCFILE = PROJ / \".coveragerc\"\n",
        "rc_opt = f\" --rcfile {RCFILE}\" if RCFILE.exists() else \"\"\n",
        "\n",
        "# ===== 모드 선택 =====\n",
        "# - \"from_38_artifacts\": 3-8 최종 산출(coverage_gen.json/xml, htmlcov_gen)을 그대로 사용 → 3-8과 동일 결과 보장\n",
        "# - \"replay_stable_k\"  : 최근 5턴 안정 통과 집합을 baseline 위에 append 실행(이전 3-9 동작)\n",
        "OUR_SOURCE_MODE = \"from_38_artifacts\"   # 기본값 권장\n",
        "STABLE_K = 5\n",
        "\n",
        "# ===== 입력/산출 경로 =====\n",
        "GOALS_FILE   = ART_DIR / \"goals_ranked.json\"        # 3-2\n",
        "RESULTS_JL   = ART_DIR / \"results.jsonl\"            # 3-8/3-5\n",
        "HISTORY_JL   = ART_DIR / \"stable_history.jsonl\"     # 3-8 누적 기록(있으면)\n",
        "\n",
        "# 3-8 최종 산출물\n",
        "COV_JSON_38 = ART_DIR / \"coverage_gen.json\"\n",
        "COV_XML_38  = ART_DIR / \"coverage_gen.xml\"\n",
        "\n",
        "# 본 단계 산출물\n",
        "COV_JSON_BASE = ART_DIR / \"coverage_pytest.json\"\n",
        "COV_XML_BASE  = ART_DIR / \"coverage_pytest.xml\"\n",
        "COV_JSON_OUR  = ART_DIR / \"coverage_our.json\"\n",
        "COV_XML_OUR   = ART_DIR / \"coverage_our.xml\"\n",
        "\n",
        "COMPARE_JSON        = ART_DIR / \"comparison_report.json\"\n",
        "FINAL_MANIFEST      = ART_DIR / \"final_comparison_manifest.json\"\n",
        "MODULE_BREAKDOWN_JS = ART_DIR / \"module_breakdown.json\"\n",
        "MODULE_BREAKDOWN_CSV= ART_DIR / \"module_breakdown.csv\"\n",
        "\n",
        "# ===== 실행 파라미터(리플레이 모드에서 사용) =====\n",
        "PY_EXE = sys.executable\n",
        "TIMEOUT_BASE = 180\n",
        "TIMEOUT_EACH = 40\n",
        "PYTEST_FLAGS = \"-q -s\"\n",
        "ENV_BASE = os.environ.copy()\n",
        "ENV_BASE[\"PYTHONPATH\"] = f\"{PROJ}:{ENV_BASE.get('PYTHONPATH','')}\"\n",
        "ENV_BASE.setdefault(\"NO_PROXY\", \"*\")\n",
        "ENV_BASE.setdefault(\"PYTHONHASHSEED\", \"0\")\n",
        "\n",
        "# ===== 유틸 =====\n",
        "def load_json(p: Path, default=None):\n",
        "    try: return json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "    except Exception: return default\n",
        "\n",
        "def rel_to_proj(p: Path) -> str:\n",
        "    try: return str(p.resolve().relative_to(PROJ))\n",
        "    except Exception: return str(p.resolve())\n",
        "\n",
        "def sh_run(cmd: str, timeout: int | None = None, cwd: Path | None = None, env: dict | None = None):\n",
        "    try:\n",
        "        p = subprocess.run(cmd, cwd=str(cwd or PROJ), env=env or ENV_BASE,\n",
        "                           shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
        "                           timeout=timeout, text=True)\n",
        "        return p.returncode, p.stdout, p.stderr, False\n",
        "    except subprocess.TimeoutExpired as e:\n",
        "        return 124, e.stdout or \"\", e.stderr or \"\", True\n",
        "\n",
        "def parse_branch_coverage(xml_path: Path) -> tuple[int,int]:\n",
        "    if not xml_path.exists(): return (0,0)\n",
        "    try:\n",
        "        root = etree.parse(str(xml_path)).getroot()\n",
        "        cv = tt = 0\n",
        "        for line in root.findall(\".//line[@branch='true']\"):\n",
        "            m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", line.get(\"condition-coverage\",\"\"))\n",
        "            if m:\n",
        "                c, t = int(m.group(1)), int(m.group(2))\n",
        "                cv += c; tt += t\n",
        "        return (cv, tt)\n",
        "    except Exception:\n",
        "        return (0,0)\n",
        "\n",
        "def per_file_branch_map(xml_path: Path) -> dict[str, dict]:\n",
        "    stats = {}\n",
        "    if not xml_path.exists(): return stats\n",
        "    try:\n",
        "        root = etree.parse(str(xml_path)).getroot()\n",
        "        for cls in root.findall(\".//class\"):\n",
        "            fn = cls.get(\"filename\") or \"\"\n",
        "            if not fn: continue\n",
        "            abs_path = (PROJ / fn).resolve() if not Path(fn).is_absolute() else Path(fn).resolve()\n",
        "            cv = tt = 0\n",
        "            for line in cls.findall(\"./lines/line[@branch='true']\"):\n",
        "                m = re.search(r\"\\((\\d+)\\s*/\\s*(\\d+)\\)\", line.get(\"condition-coverage\",\"\"))\n",
        "                if m:\n",
        "                    c, t = int(m.group(1)), int(m.group(2))\n",
        "                    cv += c; tt += t\n",
        "            if tt>0:\n",
        "                stats[str(abs_path)] = {\"covered\": cv, \"total\": tt, \"pct\": round(cv/tt*100.0,2)}\n",
        "    except Exception:\n",
        "        pass\n",
        "    return stats\n",
        "\n",
        "def line_stats_from_json(cov_json_path: Path) -> tuple[int,int,int,float]:\n",
        "    d = load_json(cov_json_path, {\"files\": {}}) or {\"files\": {}}\n",
        "    files = d.get(\"files\", {}) or {}\n",
        "    ex = ms = 0\n",
        "    for info in files.values():\n",
        "        ex += len((info or {}).get(\"executed_lines\", []) or [])\n",
        "        ms += len((info or {}).get(\"missing_lines\",  []) or [])\n",
        "    tot = ex + ms\n",
        "    pct = round(ex/tot*100.0, 2) if tot else 0.0\n",
        "    return ex, ms, tot, pct\n",
        "\n",
        "def per_file_line_map(cov_json_path: Path) -> dict[str, dict]:\n",
        "    out = {}\n",
        "    d = load_json(cov_json_path, {\"files\": {}}) or {\"files\": {}}\n",
        "    for f, info in (d.get(\"files\", {}) or {}).items():\n",
        "        ex = len((info or {}).get(\"executed_lines\", []) or [])\n",
        "        ms = len((info or {}).get(\"missing_lines\",  []) or [])\n",
        "        tot = ex + ms\n",
        "        pct = round(ex/tot*100.0, 2) if tot else 0.0\n",
        "        abs_path = (Path(f).resolve() if Path(f).is_absolute() else (PROJ / f).resolve())\n",
        "        out[str(abs_path)] = {\"executed\": ex, \"missing\": ms, \"total\": tot, \"pct\": pct}\n",
        "    return out\n",
        "\n",
        "def file_to_module(abs_path_str: str) -> str:\n",
        "    p = Path(abs_path_str).resolve()\n",
        "    try: rel = p.relative_to(PROJ)\n",
        "    except Exception: return p.name\n",
        "    return rel.stem if len(rel.parts)==1 else rel.parts[0]\n",
        "\n",
        "def aggregate_by_module(line_map: dict[str, dict], branch_map: dict[str, dict]) -> dict[str, dict]:\n",
        "    mod = {}\n",
        "    for f, s in line_map.items():\n",
        "        m = file_to_module(f)\n",
        "        slot = mod.setdefault(m, {\"line_exec\":0, \"line_total\":0, \"branch_cov\":0, \"branch_tot\":0})\n",
        "        slot[\"line_exec\"] += s.get(\"executed\",0)\n",
        "        slot[\"line_total\"]+= s.get(\"total\",0)\n",
        "    for f, s in branch_map.items():\n",
        "        m = file_to_module(f)\n",
        "        slot = mod.setdefault(m, {\"line_exec\":0, \"line_total\":0, \"branch_cov\":0, \"branch_tot\":0})\n",
        "        slot[\"branch_cov\"] += s.get(\"covered\",0)\n",
        "        slot[\"branch_tot\"] += s.get(\"total\",0)\n",
        "    out = {}\n",
        "    for m, s in mod.items():\n",
        "        lp = round(s[\"line_exec\"]/s[\"line_total\"]*100.0,2) if s[\"line_total\"]>0 else 0.0\n",
        "        bp = round(s[\"branch_cov\"]/s[\"branch_tot\"]*100.0,2) if s[\"branch_tot\"]>0 else 0.0\n",
        "        out[m] = {\"line_executed\":s[\"line_exec\"],\"line_total\":s[\"line_total\"],\"line_pct\":lp,\n",
        "                  \"branch_covered\":s[\"branch_cov\"],\"branch_total\":s[\"branch_tot\"],\"branch_pct\":bp}\n",
        "    return out\n",
        "\n",
        "def goal_hits_from_json(goals, cov_json_path: Path) -> tuple[int,int]:\n",
        "    d = load_json(cov_json_path, {\"files\": {}}) or {\"files\": {}}\n",
        "    fmap = d.get(\"files\", {}) or {}\n",
        "    def hit(fpath: str, ln: int) -> bool:\n",
        "        finfo = fmap.get(fpath) or fmap.get(str(Path(fpath).resolve()))\n",
        "        return bool(finfo) and ln in set(finfo.get(\"executed_lines\", []) or [])\n",
        "    reached = 0\n",
        "    for g in goals or []:\n",
        "        f = g[\"file\"]\n",
        "        a1 = str((PROJ / f).resolve()); a2 = f\n",
        "        tlines = g.get(\"target_lines\", []) or []\n",
        "        if any(hit(a1,ln) or hit(a2,ln) for ln in tlines):\n",
        "            reached += 1\n",
        "    return reached, len(goals or [])\n",
        "\n",
        "# ===== 1) PyTest(베이스라인) 실행/커버리지 =====\n",
        "for nm in [\".coverage\", COV_JSON_BASE.name, COV_XML_BASE.name]:\n",
        "    p = PROJ / nm\n",
        "    if p.exists(): p.unlink()\n",
        "if TESTS_DIR.exists() and any(TESTS_DIR.glob(\"test*.py\")):\n",
        "    rc, out, err, to = sh_run(f\"{PY_EXE} -m coverage run{rc_opt} -m pytest -q -s {shlex.quote(rel_to_proj(TESTS_DIR))}\",\n",
        "                              timeout=TIMEOUT_BASE)\n",
        "    (LOG_DIR / \"__cmp_pytest.out.txt\").write_text(out or \"\", encoding=\"utf-8\")\n",
        "    (LOG_DIR / \"__cmp_pytest.err.txt\").write_text(err or \"\", encoding=\"utf-8\")\n",
        "    print(\"✅ PyTest baseline 실행 PASS\" if rc==0 else f\"⚠️ PyTest rc={rc} (그래도 커버리지 산출)\")\n",
        "else:\n",
        "    print(\"ℹ️ tests/ 비어있음 → baseline 실행 건너뜀.\")\n",
        "subprocess.call(f\"coverage json -o {COV_JSON_BASE.name}{rc_opt}\", shell=True, cwd=str(PROJ))\n",
        "subprocess.call(f\"coverage xml  -o {COV_XML_BASE.name}{rc_opt}\",  shell=True, cwd=str(PROJ))\n",
        "subprocess.call(f\"coverage html -d {HTML_DIR_BASE.name}{rc_opt}\",  shell=True, cwd=str(PROJ))\n",
        "shutil.copy2(PROJ / COV_JSON_BASE.name, COV_JSON_BASE) if (PROJ / COV_JSON_BASE.name).exists() else None\n",
        "shutil.copy2(PROJ / COV_XML_BASE.name,  COV_XML_BASE)  if (PROJ / COV_XML_BASE.name).exists()  else None\n",
        "\n",
        "# ===== 2) 우리 방법 커버리지 소스 결정 =====\n",
        "if OUR_SOURCE_MODE == \"from_38_artifacts\":\n",
        "    # 3-8의 coverage_gen.*/htmlcov_gen 그대로 사용 → 3-8 결과와 완전 일치\n",
        "    if not COV_JSON_38.exists() or not COV_XML_38.exists():\n",
        "        raise SystemExit(\"coverage_gen.json/xml(3-8 산출)이 없습니다. 3-8을 먼저 완료하세요.\")\n",
        "    shutil.copy2(COV_JSON_38, COV_JSON_OUR)\n",
        "    shutil.copy2(COV_XML_38,  COV_XML_OUR)\n",
        "    our_html_index = (HTML_DIR_38 / \"index.html\").resolve()\n",
        "    print(\"📦 본 연구 커버리지: 3-8 최종 산출 그대로 사용\")\n",
        "\n",
        "else:\n",
        "    # (옵션) 최근 5턴 안정집합 리플레이 모드\n",
        "    # 필요 시 이전 3-9 코드의 pick_stable_tests_last_k 등을 그대로 붙여 넣어 사용할 수 있음\n",
        "    raise SystemExit(\"OUR_SOURCE_MODE='replay_stable_k' 지원 분기는 생략했습니다. 필요 시 알려주세요.\")\n",
        "\n",
        "# ===== 3) 지표 계산(라인/분기/목표) =====\n",
        "goals = load_json(GOALS_FILE, []) or []\n",
        "base_exec, base_miss, base_total, base_line_pct = line_stats_from_json(COV_JSON_BASE)\n",
        "our_exec,  our_miss,  our_total,  our_line_pct  = line_stats_from_json(COV_JSON_OUR)\n",
        "\n",
        "base_bcov, base_btot = parse_branch_coverage(COV_XML_BASE)\n",
        "our_bcov,  our_btot  = parse_branch_coverage(COV_XML_OUR)\n",
        "base_branch_pct = round(base_bcov/base_btot*100.0, 2) if base_btot else 0.0\n",
        "our_branch_pct  = round(our_bcov/our_btot*100.0,  2) if our_btot  else 0.0\n",
        "\n",
        "reached_base, total_goals = goal_hits_from_json(goals, COV_JSON_BASE)\n",
        "reached_our,  _           = goal_hits_from_json(goals, COV_JSON_OUR)\n",
        "\n",
        "# ===== 4) 모듈별 리포트 =====\n",
        "base_line_map   = per_file_line_map(COV_JSON_BASE)\n",
        "our_line_map    = per_file_line_map(COV_JSON_OUR)\n",
        "base_branch_map = per_file_branch_map(COV_XML_BASE)\n",
        "our_branch_map  = per_file_branch_map(COV_XML_OUR)\n",
        "\n",
        "def aggregate_by_module(line_map, branch_map):\n",
        "    mod = {}\n",
        "    for f, s in line_map.items():\n",
        "        m = file_to_module(f)\n",
        "        slot = mod.setdefault(m, {\"line_exec\":0,\"line_total\":0,\"branch_cov\":0,\"branch_tot\":0})\n",
        "        slot[\"line_exec\"] += s[\"executed\"]; slot[\"line_total\"] += s[\"total\"]\n",
        "    for f, s in branch_map.items():\n",
        "        m = file_to_module(f)\n",
        "        slot = mod.setdefault(m, {\"line_exec\":0,\"line_total\":0,\"branch_cov\":0,\"branch_tot\":0})\n",
        "        slot[\"branch_cov\"] += s[\"covered\"]; slot[\"branch_tot\"] += s[\"total\"]\n",
        "    out = {}\n",
        "    for m, s in mod.items():\n",
        "        lp = round(s[\"line_exec\"]/s[\"line_total\"]*100.0,2) if s[\"line_total\"]>0 else 0.0\n",
        "        bp = round(s[\"branch_cov\"]/s[\"branch_tot\"]*100.0,2) if s[\"branch_tot\"]>0 else 0.0\n",
        "        out[m] = {\"line_executed\":s[\"line_exec\"],\"line_total\":s[\"line_total\"],\"line_pct\":lp,\n",
        "                  \"branch_covered\":s[\"branch_cov\"],\"branch_total\":s[\"branch_tot\"],\"branch_pct\":bp}\n",
        "    return out\n",
        "\n",
        "base_by_module = aggregate_by_module(base_line_map, base_branch_map)\n",
        "our_by_module  = aggregate_by_module(our_line_map,  our_branch_map)\n",
        "\n",
        "modules = sorted(set(base_by_module.keys()) | set(our_by_module.keys()))\n",
        "rows = []\n",
        "for m in modules:\n",
        "    b = base_by_module.get(m, {\"line_total\":0,\"line_pct\":0.0,\"branch_total\":0,\"branch_pct\":0.0})\n",
        "    o = our_by_module.get(m,  {\"line_total\":0,\"line_pct\":0.0,\"branch_total\":0,\"branch_pct\":0.0})\n",
        "    rows.append({\n",
        "        \"module\": m,\n",
        "        \"pytest_line_pct\": b[\"line_pct\"], \"our_line_pct\": o[\"line_pct\"],\n",
        "        \"delta_line_pct\": round(o[\"line_pct\"] - b[\"line_pct\"], 2),\n",
        "        \"pytest_branch_pct\": b[\"branch_pct\"], \"our_branch_pct\": o[\"branch_pct\"],\n",
        "        \"delta_branch_pct\": round(o[\"branch_pct\"] - b[\"branch_pct\"], 2),\n",
        "        \"pytest_line_measured\": b.get(\"line_total\",0), \"our_line_measured\": o.get(\"line_total\",0),\n",
        "        \"pytest_branch_total\": b.get(\"branch_total\",0), \"our_branch_total\": o.get(\"branch_total\",0),\n",
        "    })\n",
        "\n",
        "MODULE_BREAKDOWN_JS.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "with MODULE_BREAKDOWN_CSV.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"module,pytest_line_pct,our_line_pct,delta_line_pct,pytest_branch_pct,our_branch_pct,delta_branch_pct,pytest_line_measured,our_line_measured,pytest_branch_total,our_branch_total\\n\")\n",
        "    for r in rows:\n",
        "        f.write(\"{module},{pytest_line_pct},{our_line_pct},{delta_line_pct},{pytest_branch_pct},{our_branch_pct},{delta_branch_pct},{pytest_line_measured},{our_line_measured},{pytest_branch_total},{our_branch_total}\\n\".format(**r))\n",
        "\n",
        "# ===== 5) 비교/델타 요약 =====\n",
        "comparison = {\n",
        "    \"pytest_baseline\": {\n",
        "        \"lines\": {\"executed\": base_exec, \"missing\": base_miss, \"measured\": base_total, \"line_coverage_pct\": base_line_pct},\n",
        "        \"branches\": {\"covered\": base_bcov, \"total\": base_btot, \"branch_coverage_pct\": base_branch_pct},\n",
        "        \"goals\": {\"reached_any\": reached_base, \"total\": total_goals,\n",
        "                  \"goal_success_pct\": round((reached_base/total_goals*100.0) if total_goals>0 else 0.0, 2)},\n",
        "        \"html_index\": str((HTML_DIR_BASE / \"index.html\").resolve())\n",
        "    },\n",
        "    \"our_method\": {\n",
        "        \"lines\": {\"executed\": our_exec, \"missing\": our_miss, \"measured\": our_total, \"line_coverage_pct\": our_line_pct},\n",
        "        \"branches\": {\"covered\": our_bcov, \"total\": our_btot, \"branch_coverage_pct\": our_branch_pct},\n",
        "        \"goals\": {\"reached_any\": reached_our, \"total\": total_goals,\n",
        "                  \"goal_success_pct\": round((reached_our/total_goals*100.0) if total_goals>0 else 0.0, 2)},\n",
        "        \"html_index\": str((HTML_DIR_38 / \"index.html\").resolve()) if OUR_SOURCE_MODE==\"from_38_artifacts\"\n",
        "                      else str((HTML_DIR_OUR / \"index.html\").resolve())\n",
        "    },\n",
        "    \"deltas(our_minus_pytest)\": {\n",
        "        \"lines\": {\n",
        "            \"executed_delta\": our_exec - base_exec,\n",
        "            \"missing_delta\":  base_miss - our_miss,\n",
        "            \"line_coverage_pct_delta\": round(our_line_pct - base_line_pct, 2)\n",
        "        },\n",
        "        \"branches\": {\n",
        "            \"covered_delta\": our_bcov - base_bcov,\n",
        "            \"total_delta\":   our_btot - base_btot,\n",
        "            \"branch_coverage_pct_delta\": round(our_branch_pct - base_branch_pct, 2)\n",
        "        },\n",
        "        \"goals\": {\n",
        "            \"reached_delta\": reached_our - reached_base,\n",
        "            \"goal_success_pct_delta\": round(((reached_our - reached_base) / total_goals * 100.0), 2) if total_goals>0 else 0.0\n",
        "        }\n",
        "    },\n",
        "    \"module_breakdown_paths\": {\"json\": str(MODULE_BREAKDOWN_JS), \"csv\": str(MODULE_BREAKDOWN_CSV)},\n",
        "    \"mode\": OUR_SOURCE_MODE\n",
        "}\n",
        "(Path(ART_DIR) / \"comparison_report.json\").write_text(json.dumps(comparison, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n📊 최종 비교 요약 (PyTest vs 본 연구; mode =\", OUR_SOURCE_MODE, \")\")\n",
        "print(f\"- 라인 커버리지:   PyTest {comparison['pytest_baseline']['lines']['line_coverage_pct']}%  |  본 연구 {comparison['our_method']['lines']['line_coverage_pct']}%  |  Δ {comparison['deltas(our_minus_pytest)']['lines']['line_coverage_pct_delta']}%p\")\n",
        "print(f\"- 분기 커버리지:   PyTest {comparison['pytest_baseline']['branches']['branch_coverage_pct']}% |  본 연구 {comparison['our_method']['branches']['branch_coverage_pct']}% |  Δ {comparison['deltas(our_minus_pytest)']['branches']['branch_coverage_pct_delta']}%p\")\n",
        "print(f\"- 목표 달성률:     PyTest {comparison['pytest_baseline']['goals']['goal_success_pct']}% |  본 연구 {comparison['our_method']['goals']['goal_success_pct']}% |  Δ {comparison['deltas(our_minus_pytest)']['goals']['goal_success_pct_delta']}%p\")\n",
        "print(f\"- 모듈별 리포트: {MODULE_BREAKDOWN_JS.name}, {MODULE_BREAKDOWN_CSV.name}\")\n",
        "\n",
        "FINAL_MANIFEST = ART_DIR / \"final_comparison_manifest.json\"\n",
        "FINAL_MANIFEST.write_text(json.dumps({\n",
        "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"project\": str(PROJ),\n",
        "    \"run_dir\": str(ART_DIR),\n",
        "    \"artifacts\": {\n",
        "        \"pytest\": {\n",
        "            \"coverage_json\": str(COV_JSON_BASE),\n",
        "            \"coverage_xml\": str(COV_XML_BASE),\n",
        "            \"coverage_html_index\": str((HTML_DIR_BASE / \"index.html\").resolve()),\n",
        "            \"log_out\": str((LOG_DIR / \"__cmp_pytest.out.txt\").resolve()),\n",
        "            \"log_err\": str((LOG_DIR / \"__cmp_pytest.err.txt\").resolve()),\n",
        "        },\n",
        "        \"our_method\": {\n",
        "            \"coverage_json\": str(COV_JSON_OUR),\n",
        "            \"coverage_xml\": str(COV_XML_OUR),\n",
        "            \"coverage_html_index\": str((HTML_DIR_38 / \"index.html\").resolve()) if OUR_SOURCE_MODE==\"from_38_artifacts\"\n",
        "                                   else str((HTML_DIR_OUR / \"index.html\").resolve()),\n",
        "        },\n",
        "        \"comparison_json\": str(COMPARE_JSON),\n",
        "        \"module_breakdown_json\": str(MODULE_BREAKDOWN_JS),\n",
        "        \"module_breakdown_csv\":  str(MODULE_BREAKDOWN_CSV),\n",
        "        \"mode\": OUR_SOURCE_MODE\n",
        "    }\n",
        "}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"✅ 최종 비교 산출 완료\")\n"
      ],
      "metadata": {
        "id": "HHH8zKU7xzzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469659fd-b44d-4aa4-c4bc-a99c6724495d"
      },
      "id": "HHH8zKU7xzzw",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PyTest baseline 실행 PASS\n",
            "📦 본 연구 커버리지: 3-8 최종 산출 그대로 사용\n",
            "\n",
            "📊 최종 비교 요약 (PyTest vs 본 연구; mode = from_38_artifacts )\n",
            "- 라인 커버리지:   PyTest 65.38%  |  본 연구 75.0%  |  Δ 9.62%p\n",
            "- 분기 커버리지:   PyTest 60.0% |  본 연구 80.0% |  Δ 20.0%p\n",
            "- 목표 달성률:     PyTest 0.0% |  본 연구 20.0% |  Δ 20.0%p\n",
            "- 모듈별 리포트: module_breakdown.json, module_breakdown.csv\n",
            "✅ 최종 비교 산출 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TiTUpEZcBSxq"
      },
      "id": "TiTUpEZcBSxq",
      "execution_count": null,
      "outputs": []
    }
  ]
}